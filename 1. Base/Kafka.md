+ [Структура](#структура)
+ [Преимущества Kafka](#преимущества-kafka)
+ [Производитель](#производитель)
+ [Потребитель](#потребитель)
+ [AdminClient](#adminclient)
+ [Внутреннее устройство](#adminclient)

## Структура

+ [1. Сообщение и пакеты](#1-сообщение-и-пакеты)
+ [2. Топики и разделы](#2-топики-и-разделы)
+ [3. Производители и потребители](#3-производители-и-потребители)
+ [4. Брокеры и кластеры](#4-брокеры-и-кластеры)
+ [5. Несколько кластеров](#5-несколько-кластеров)


### 1. Сообщение и пакеты
Сообщение представляет собой массив байтов. Представляет собой пару ключ/значение

Ключ - В сообщении может быть дополнитеьный фрагмет метаданных. Представляет собой тоже массив байтов
Ключи используются при необходимости лучше управлять записью сообщений в разделы и для сохранения порядка.
При передаче ключа, сообщение будет записано ровно в том порядке, в котором было передано.
Все сообщения с одиннаковым ключем попадут в один раздел. Это значит, если каждый процесс читает лишь часть разделов топика, все записи для конкретного ключа будет читать один и тот же процесс

Для эффективности сообщения записываются пакетами
Пакет (batch) представляет собой набор сообщений, относящихся к одному топику и разделу

### 2. Топики и разделы
Сообщения распределяются по топикам (topics)
Топики разбиваются на разделы (partitions)

Раздел представляет собой отдельный журнал
Сообщения записываются в него путем добавления в конец, а читаются по порядку от начала к концу

Любой из разделов можно разместить на отдельном сервере

### 3. Производители и потребители
Производители(producers) - генерируют новые сообщения. Производители сообщений создают их для конкретного топика. 
По умолчанию производитель будет равномерно поставлять сообщения во все разделы топика. 
В некоторых случаях он будет направлять сообщение в конкретный раздел. Для этого служат клют сообщения и объект Partitioner
Partitioner - генерирует хеш ключа и у станавливает его соотвестветствие с конкретным разделом. Это гарантирует запись всех сообщений с одиннаковым ключем в один и тот же раздел

Потребители(consumer) - читают сообщения.
Потребитель подписывается на один или более топиков и читает сообщения в корядке их создания в каждом разделе
Он ослеживает уже прочитанные сообщения, запоминая смещение сообщений
Смещение(offset) - непрерывно возрастающее целочисленное значение - элемент метаданных

Потребители работают в составе групп потребителей (consumer group) - одного или нескольких потребителей, объединенных для обработки топика
Организация в группы гарантирует чтение каждого раздела только одним членом группы.
Таким образом появляется возможность горизонтального масштабирования
В случае сбоя отдельного потребителя, оставшиеся члены группы переназначат потребляемые разделы

### 4. Брокеры и кластеры
Блокер(broker) - отдельный сервер Kafka
- Получает сообщения от производителей, присваивает им смещения и записывает в дисковое хранилище.
- Обслуживает потребителей и отвечает на запросы выборки из разделов, возвращая опубликованные сообщения

Блокеры предназначны для работы в составе _кластера_ (cluster)
Один из брокеров кластера функционрирует в качестве _контроллера_(cluster controller)
Контроллер кластера - выбираетсч автоматически из числа работающих членов кластера. 
    Отвечает за административные операции, включая распределение разделов по брокерам и мониторинг отказов брокеров

Каждый раздел принадлежи  одному из брокеров кластера, который называется ведущим (leader).
Реплицированный раздел можно назначить дополнительным брокерам, которые называются _последователями_(fillowers)
Все последователи полжны соединяться с ведущим для публикации сообщений
Потребители могут получать сообщения либо от ведущего, либо от одного из последователей

### 5. Несколько кластеров
Причины для нескольких кластеров:
- Разделение типов данных
- Изоляция по требованиям безопасности
- Несколько центров обработки данных (ЦОД)

Проект Kafka MirrorMaker позволяет реплицировать данные на другие кластера
Сообщения из двух локальных кластеров агрегируются в составной кластер, который затем копируется в другие ЦОД

## END ---------------- Структура ----------------

## Преимущества Kafka

+ [1. Несколько производителей](#1-несколько-производителей)
+ [2. Несколько потребителей](#2-несколько-потребителей)
+ [3. Сохранение информации на диске](#3-сохранение-информации-на-диске)
+ [4. Масштабируемость](#4-масштабируемость)
+ [5. Высокое быстродействие](#5-высокое-быстродействие)

### 1. Несколько производителей
Может работать с несколькими производителями, даже если они используют разные топики
Это позволяет агрегировать данные из множества клиенских систем и обеспечивает их согласованность

### 2. Несколько потребителей
Несколько потребителей могут читать любой одтин поток сообщений, не мешая друг другу

### 3. Сохранение информации на диске
Предполагает долговременное хранение данных и возможность чтение не в реальном времени
Правила хранения можно задать для каждого топика по отдельности

### 4. Масштабируемость
Благодаря горизонтальному масштабированию на каждом этапе структуры можно без проблем масштабировать в ходе развития системы

### 5. Высокое быстродействие
Благодаря схеме "Публикация/Подписка" получается отличная производительность при высокой нагрузке


## END ---------------- Преимущества Kafka ----------------

## Производитель

+ [1. Структура производителя](#1-структура-производителя)
+ [2. Обязательные свойства производителей](#2-обязательные-свойства-производителей)
+ [3. Пример создания нового производителя](#3-пример-создания-нового-производителя)
+ [4. Методы отправки сообщений](#4-методы-отправки-сообщений)
+ [5. Пример отправки сообщений](#5-пример-отправки-сообщений)
+ [6. Синхронная отправка сообщений](#6-синхронная-отправка-сообщений)
+ [7. Типы ошибок в KafkaProducer](#7-типы-ошибок-в-kafkaproducer)
+ [8. Асинхронная отправка сообщения](#8-асинхронная-отправка-сообщения)
+ [9. Разделы](#9-разделы)
+ [10. Заголовки](#10-заголовки)
+ [11. Перехватчики](#11-перехватчики)

### 1. Структура производителя
``````
                        ProducerRecord
                            Топик
  -------------------->    [Раздел]
 |         |                [Ключ]
 |         |                Значение
 |         |                    |
 В         |                    | send()
 случае    |                    V
 успех     |                Сериализатор
 возвращает|                    |
 метаданные|                    |
 |         |                    V
 |         |                Объект Partitioner
 |         |                |                    |
 |         |                |                    |
 |        Повторяем         V                    V
 |        попытку? ---> Топик А                Топик Б
 |         ^        да  Раздел 0               Раздел 1
 |         |            [Пакет 0]              [Пакет 0]
 |         |            [Пакет 1]              [Пакет 1]
 -----  Неудача?        [Пакет 2]              [Пакет 2]
           ^                        |
           |                        | 
           |                        V
           -------------------  Брокер Kafka
``````

1. Для генерации сообщений понадобится создать объект `ProducerRecord`, включающий топик, в который мы собираемся отправить запись и значение
2. Можно так же задать ключ и разде, временную метку и/или набор заголовков
3. После отправки происходит сериализация объекта ключа и значения в байтовые массивы для отправки по сети
4. Если разделы явно не указаны, данные попадают в объект `Partitioner`
5. Объект `Partitioner` выбирает раздел,  в соответствии с ключом из `ProducerRecord`
6. Если раздел выбран, то производитель будет знать в какой топик и раздел должна попасть запись
7. После запись помещается в пакет записей, предназначенных ддя отправки в топик и раздел
8. За отправку пакетов записей соответствующему брокеру Kafka отвечает отдельный поток выполнения
9. После получения сообщений брокер отправляет ответ
10. В случае успеха возвращается объект `RecordMetadata` содержащий топик, раздел и смещение записи в разделе
11. При неудаче будет возвращено сообщение об ошибке

### 2. Обязательные свойства производителей
- `bootstrap.servers` - список пар host:port брокеров, исользуемых производителем для первоначального соединения с кластером
  Производитель может получать дополнительную информацию после начального соединения. Рекомендуется включить хотя бы два брокера
- `key.serializer` - имя класса, применяемого для сериализации ключени записей, генерируемых для отправки в Kafka
  Значением должно быть имя класса, реализующего интерфейс `org.apache.kafka.common.serialization.Serializer` 
- `value.serializer` - имя класса, используемого для сериализации значений записей

### 3. Пример создания нового производителя
```java
Properties kafkaProps = new Properties(); // (1)
kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");

kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // (2)
kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); 

producer = new KafkaProducer<String, String>(kafkaProps);// (3)
```

1. Начинаем с объекта `Properties`
2. Мы планируем использовать строки для ключа и значения сообщения, поэтому подойдет `StringSerializer`
3. Создаем новый поизводитель, задавая подходящие типы ключа и значения и передавая в конструктор объект Properties

### 4. Методы отправки сообщений
1. Сделать и забыть - Отправляем сообщение на сервер, после чего особо не волнуемся дошло или нет
   В случае ошибок или таймауста сообщение будет потеряно и информации о потере не будет
2. Синхронная отправка - Производитель Kafka всгда асинхронный - метод send() возвращает объект класса Future
   Можно воспользоваться методом get() для ожидания ответа
3. Асинхронная отправка - вызываем send(), которому передается функция обратного вызова при получении ответа

### 5. Пример отправки сообщений
```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France"); // (1)

try {
  producer.send(record); // (2)
} catch (Exception e) {
  e.printStackTrace(); // (3)
}
```

1. Производитель получает на фходе объекты `ProducerRecord`, поэтому начинаем с создания самого объекта
   Используется конструктор, принимающий на входе - название топика, ключ и значение
2. Для отправки используется метод send(), который возвращает объект класса Future
3. Выводит потенциальные ошибки

### 6. Синхронная отправка сообщений
При синхронной отправке тратится время на ожидаение ответа и блокируется весь поток выполнения
```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");

try {
  producer.send(record).get(); // (1)
} catch (Exception e) {
  e.printStackTrace(); // (2)
}
```

1. Используется метод Future.get() для ожидания ответа от Kafka
   Метод генерирует исключение в случае неудачи отправки записи.
    При отсутствии ошибок мы получим объект `RecordMetadata`
2. Если перед отправкой или во время отправки записи возникли ошибки, то мы получим исключение и выведем информацию о нем

### 7. Типы ошибок в KafkaProducer
1. Ошибки, которые можно исправить, отправив сообщение повторно (repitable)
   Например, ошибка соединения, ошибка "отсутствует ведущий узел для раздела"
2. Ошибки, которые невозможно исправить
    Например, "сообщение слишком велико"

### 8. Асинхронная отправка сообщения
Для асихронной отправки сообщений с сохранением возможности обработки различных сценариев ошибок производителя поддерживают функции обратного вызова при оправке записи

```java
private class DemoProducerCallback implements Callback { // (1)
  @Override
  public void onComletion (RecordMetadata recordMetadata, Exception e) {
    if (e != null) {
      e.printStackTrace(); // (2)
    }
  }
}

ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Biomedical Materials", "USA"); // (3)
producer.send(record, new DemoProducerCallback()); // (4)
```

1. Для использования функций обратного вызов понадобится класс, реализующий интерфейс `org.apache.kafka.clients.producer.Callback`
2. Если Kafka вернет ошибку, в функцию `onCompetion()` попадет непустое исключение
3. Записи остаются такими же как и при синхронном вызове
4. Передаем Callback при отправке записи

### 9. Разделы

+ [1. Зачем нужны разделы](#1-зачем-нужны-разделы)
+ [2. Пример создания сообщения с ключем](#2-пример-создания-сообщения-с-ключем)
+ [3. Что используется для балансировки сообщений](#3-что-используется-для-балансировки-сообщений)
+ [4. Реализация Partitioner](#4-реализация-partitioner)

#### 1. Зачем нужны разделы
1. Каждый топик может иметь 1 или больше разделов, которые распределяются по разным узлам кластера (брокерам)
Это позволяет нескольким потребителям считывать данные из одного топика одновременно
2. Если число потребителей меньше числа разделов, один consumer получает сообщения из нескольких разделов
3. Если потребителей больше, чем разделов, нескоторые consumer не получат никаких сообщений, пока общее количество потребителей не снизится до количества разделов
4. На пратике максимальное число разделов ограничивается размером сохраняемых сообщений, которые могут поместиться на одном узле
   Теоретически максимальное количество разделов может быть любым
5. Чтобы повысить надежность и доступность данных в кластере Kafka, разедлы могут иметь копии
6. Число разделов и коэффициент репликации можно настроить для всего класеа или для кадого топика отдельно


#### 2. Пример создания сообщения с ключем
```java
ProducerRecord<String String> record = new ProducerRecord<>("CustomerCountry", "Labratory Equipment", "USA")
```
без ключа
```java
ProducerRecord<String String> record = new ProducerRecord<>("CustomerCountry", "USA")
```

#### 3. Что используется для балансировки сообщений
Если ключ не указан, то запись будет отправлена в один из доступных рахделов топика случайным образом
Для балансировки сообщений по разделам будет применяться циклический алгорит (round-robin)
Начиная с весрии 2.4 циклический алгоритм является "липким". Это означает, что он будет заполнять пакет сообщений, отправленных в один раздел, прежде чем переключиться на следующий.

Если ключ указан, то будет вычислено хеш-значение с помощью собственного алгоритма хеширования, так что хеш-значение не изменяется при обновлении Java

#### 4. Реализация Partitioner
```java
import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.record.InvalidRecordException;
import org.apache.kafka.common.utils.Utils;

public class BananaPartitioner implements Partitioner {
  public void configure (Map<String, ?> configs) {} // 1()
  
  public int partition (String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
    int numPartitions = partitions.size();
    
    if ((keyBytes == null) || (!(ky instanceof String))) { // (2)
      throw new InvalidRecordException("We expect all messages to have customer name as key");
    }
    
    if ((String) key.equals("Banana")) {
      return numPartitions - 1; // Banana всегда попадает в последний раздел
    }
    
    // Другие записи рспределяются по разделам хеширования
    return Math.abs(this.murmur(keyBytes)) % (numPartitions - 1);
  }
}
```

1. Интерфейс объекта секционирования включает методы configure, partition и close.
2. Мы ожидаем только токовые ключи, иначе генерируем исключение

### 10. Заголовки

Записи могут включать в себя заголовки.
Заголовки могут содержать некоторые метаданные о записи
Используются например для указания источника данных в записи, а также для маршрутизации или отслеживания сообщений на основе информации заголовка

Представлены в виде коллекции "ключ/значение".
Ключи всегда являются строками, а значениями могут быть любые сериализованные объекты

```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");

record.headers().add("privacy-level","YOLO".getBytes(StandardCharsets.UTF_8));
```

### 11. Перехватчики

Перехватчики используются для измененияповедения клиенского приложения, без изменения кода

ProducerInterceptop включают два ключевых метода:
- ProducerRecord<K, V> onSend(ProducerRecord<K, V> record) - метод будет вызван до того, как созданная запись будет отправлена.
    Переобпределяя метод можно получить информацию об отправленной записи и даже изменить ее
- void onAcknowledgement(RecordMetadata metadata, Exception exception) - метод будет вызван, если и когда ответит подтверждением на автоотправку

Примеры использования:
- Сбор информации для мониторинга и отслеживания
- Дополнение сообщения стандартными заголовками
- Редактирование конфиденциальной информации

Пример:
```java
public class CountingProducerIntercepor implements ProducerInterceptor {
  ScheduledExecutorService executorService = Executors.newSingleThreadScheduledExecutor();
  static AtomicLong numSent = new AtomicLong(0);
  static AtomicLong numAcked = new AtomicLong(0);

  public void configure(Map<String, ?> map) {
    Long windowSize = Long.valueOf((String) map.get("counting.interceptor.window.size.ms")); // (1)
    executorService.scheduleAtFixedRate(CountingProducerInterceptor::run, windowSize, windowSize, TimeUnit.MILLISECONDS);
  }

  public ProducerRecord onSend(ProducerRecord producerRecord) {
    numSent.incrementAndGet();
    return producerRecord; // (2)
  }

  public void onAcknowledgement(RecordMetadata recordMetadata, Exception e) {
    numAcked.incrementAndGet(); // (3)
  }
  
  public void close() {
    executorService.shutdownNow(); // (4)
  }
  
  public static void run() {
    System.out.println(numSent.getAndSet(0));
    System.out.println(numAcked.getAndSet(0));
  }
}
```

1. ProducerInterceptor - это настраиваемый интерфейс. Можно переопределить метод confgure и выполнить настройку перед вызовом любого другого метода
2. Когда запись отправлена, увеличиваем счетчик записей и возвращаем запись
3. Когда Kafka отвечает подтверждением получения, увеличивем счетчик подтверждений и не должны ничего возвращать
4. Метод вызывается когда производитель закрывается. В данном случае мы закрываем открытый поток. 

## END ---------------- Производитель ----------------

## Потребитель

+ [1. Группа потребителей](#1-группа-потребителей)
+ [2. Способы масштабирования](#2-способы-масштабирования)
+ [3. Как происходит перебалансировка разделов](#3-как-происходит-перебалансировка-разделов)
+ [4. Как потребители поддерживают членство в группе](#4-как-потребители-поддерживают-членство-в-группе)
+ [5. Что происходит когда потребители присоединяются к группу](#5-что-происходит-когда-потребители-присоединяются-к-группу)
+ [6. Статические участники группы](#6-статические-участники-группы)
+ [7. Создание потребителя](#7-создание-потребителя)
+ [8. Подписка на топик](#8-подписка-на-топик)
+ [9. Фиксация смещения](#9-фиксация-смещения)
+ [10. Прослушивание на предмет перебалансировки](#10-прослушивание-на-предмет-перебалансировки)
+ [11. Особенности событий при совместной перебалансировке](#11-особенности-событий-при-совместной-перебалансировке)
+ [12. Использование `onPartitionsRevoked()`](#12-использование-onpartitionsrevoked)
+ [13. Получение записей с заданным смещением](#13-получение-записей-с-заданным-смещением)
+ [14. Выход из цикла](#14-выход-из-цикла)
+ [15. Автономный потребитель](#15-автономный-потребитель)

### 1. Группа потребителей
Если несколько потребителей подписаны на один топик и относятся к одной группе, все они будут получать сообщения из различных подмножеств разделов группы

Пример:
Топик Т1 с 4мя разделами
    - Раздел 0
    - Раздел 1
    - Раздел 2
    - Раздел 3

Потребитель C1 - единственный потребитель в группе G1 и подписан на топик T1

Если мы добавим в G1 еще один потребитель C2
    то каждый потребитель будет получать сообщения только из двух разделов

Если в группе G1 будет 4 потребителя, то каждый из них будет читать сообщения из своего раздела

T1                        G1
- Раздел 0   ---->   - Потребитель 1
- Раздел 1   ---->   - Потребитель 2
- Раздел 2   ---->   - Потребитель 3
- Раздел 3   ---->   - Потребитель 4

Если же потребителей в группе G1 будет больше чем разделов в топике, то потребители часто будут простаивать и вообще не получать сообщения

### 2. Способы масштабирования
Чаще всего потребители выполняют операции с высокой задержкой, т.е. потребитель будет отставать от темпов поступления данных в топик
Основной метод масштабировани - добавление новых потребителей, каждый из которых отвечает лишь за часть разделов и сообщений

### 3. Как происходит перебалансировка разделов
Перебалансировка - передача раздела от одного потребителя другому
- Добавленный в группу потребитель начинает получать сообщения из разделов, за которые ранее отвечал другой потребитель
- То же самое происходит если потребитель останавливается или аварийно завершается
- Переназначение разделов потребителям происходит также при изменении топиков

Типы перебалансировки:
1. Безотлагательная перебалансировка - Все потребители прекращают потребление, отказываются от своих прав владения всеми разделами
   снова присоединяются к группе потребителей и получают совершенно новое назначение разделов
2. Совместная перебалансировка (инкрементная перебалансировка) - переназначение лишь небольшого подмножества разделов от одного потребителя к другому
    и позволяет потребителям продожать обработку записей из всех разделов, которые не были переназначены
    - Сначала лидер группы потребителей собщает всем потребителям, что они потеют право владения подмножеством свих разделов
    - Потребители прекращают потребление из этих разделов
    - Отказывается от своего права владния ими
    - Лидер назначает эти осиротевшие разделы их новым владельцам

### 4. Как потребители поддерживают членство в группе
Потребители отправляют назначенному координатором группы брокеру Kafka переодических контрольных сигналов (heartbeats)
Если потребитель длительное время не отправляет сигналы, время его сеанса истекает, координатор группы признает его неработающим и инициирует перебалансировку

### 5. Что происходит когда потребители присоединяются к группу
- Потребитель отправляет сигнал координатору группы запрос JoinGroup
- Первый присоединившийся к группе потребитель становится ведущим потребителем группы
- Ведущий потребитель группы получает от координатора список всех потребителей, которые недавно отправляли контрольные сигналы
- Для определения того, за какие разделы какой потребитель должен отвечать, используется реализация класса PartitionAssignor
- Происходит распределение разделов
- После распределения разделов лидер группы потребителей отправляет список назначений координатору группы, которые пересылает информацию потребителям

### 6. Статические участники группы

+ [1. Как настроить статического участника группы](#1-как-настроить-статического-участника-группы)
+ [2. Что происходит при присоединении, выключении участника](#2-что-происходит-при-присоединении-выключении-участника)
+ [3. Можно ли иметь два статического участника с одиннаковыми идентификаторами](#3-можно-ли-иметь-два-статического-участника-с-одиннаковыми-идентификаторами)
+ [4. В каких кейса использовать статических участников](#4-в-каких-кейса-использовать-статических-участников)

#### 1. Как настроить статического участника группы
Настроить потребителя с уикальным идентификатором `group.instance.id`

#### 2. Что происходит при присоединении, выключении участника
Когда потребитель впервые присоединяется к группе потребителей ему назначается набор разделов в соответствии со стратегией назначения разделов
Когда поребитель выключается, он не покидает группу автоматически - он остается членом до тех пор, пока его сессия не завершится
Когда потребитель снова присоединяется к группе, он распознается со своей статическом идентификацией и ему переназначаются те же разделы, которые он занимал ранее, без перебалансировки

#### 3. Можно ли иметь два статического участника с одиннаковыми идентификаторами
Нет. второй отребитель получит ошибку

#### 4. В каких кейса использовать статических участников
Когда приложение поддерживает локальное состояние или кеш и повторное создание кэша занимает много времени


### 7. Создание потребителя
Три обязательных свойства:
    bootstrap.servers - строка подключения к кластеру
    key.deserializer - класс для десериализации
    value.deserializer - класс для десериализации

Пример:
```java
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9092");
props.put("group.id", "CountryCounter");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);
```

### 8. Подписка на топик
```java
consumer.subscribe(Collections.singletonList("customerCountries")); //(1)
```
1. Создаем список, содержащий один элемент - название топика "consumerCountries"

Можно вызвать метод sbscribe с регулярным выражением для подписки на несколько топиков

```java
consumer.subscribe(Pattern.compile("test.*"));
```
!Note: При подписке через регулярное выражение, потребитель будет запрашивать весь список топиков и их разделов у брокеров через регулярные промежутки времени
Затем клиент будет использовать полученный список для обнаружения новых топиков, которые он включит в свою подписку


### 9. Фиксация смещения

+ [1. Что такое смещение](#1-что-такое-смещение)
+ [2. Как потребители фиксируют смещение](#2-как-потребители-фиксируют-смещение)
+ [3. Как влияет смещение на перебалансировку](#3-как-влияет-смещение-на-перебалансировку)
+ [4. Как работает автоматическая фиксация](#4-как-работает-автоматическая-фиксация)
+ [5. Синхронная фиксация смещения](#5-синхронная-фиксация-смещения)
+ [6. Асинхронная фиксация](#6-асинхронная-фиксация)
+ [7. Сочетание синхронной и асинхронной фиксации](#7-сочетание-синхронной-и-асинхронной-фиксации)
+ [8. Фиксация заданного смещения](#8-фиксация-заданного-смещения)

#### 1. Что такое смещение
Фиксация смещения - это обновление текущей позиции потребителя в разделах
Kafka не фиксирует записи по отдельности
Потребители фиксируют последнее сообщение, которое они успешно обработали из раздела

#### 2. Как потребители фиксируют смещение
Они отправляют сообщение в Kafka, которое обновляет специальный топик `__consumer_offers`
`__consumer_offers` - содержит смещение для каждого из разделов

#### 3. Как влияет смещение на перебалансировку
После перебалансировки каждому из потребителей может быть назначен набор разделов, отличный от обрабатываемых ранее
Чтобы знать, с какого места продолжать работу, потребитель должен прочитать оттуда последнее зафиксированное смещение для каждого из разделов и продолжать оттуда

* Если зафиксированное смещение меньше смещения последнего обработанного клиентом сообщение, то расположенные между ними сообщения будут обработаны дважды
* Если зафиксированное смещение превышает смещение последнего обработаного клиентом события, то расположенные в этом промежутке сообщения будут пропущены группой поребителей

#### 4. Как работает автоматическая фиксация
При значени `enable.auto.commit = true` потребитель каждые 5с будет автоматически фиксировать самое последнее смещение, возвращенное клиенту метдом poll()
Значение 5с можно изменить `auto.commit.interval.ms`

В основе автоматической фиксации лежит цикл опроса.
    - При каждом опросе потребитель проверяет не пора ли выполнить фиксацию
    - Если да, фиксирует возвращенные при послежнем опросе смещения

Кейс:
После последней фиксации прошло 3с и потребитель вышел из строя
После перебалансировки выжившие потребители начнкт потреблять разделы, которые ранее принадлежали вышедшему из сроя брокуру
Они будут получать данные с последнего зафиксированного смещения
То есть события последних 3с будут обработаны дважды

#### 5. Синхронная фиксация смещения
Отключить автоматическую фиксацию можно `enable.auto.commit = false`
Простейщий способ фиксации `commitSync()`
Он фиксирует последнее возвращенное методом `poll()` смещение и сразу завершает выполнние процедуры

Пример:
```java
while(true) {
  ConsumerRecords<String, String> records = consumer.poll(timeout);
  
  for (ConsumerRecord<String, String> record: records) {
      System.out.printf("topic = %s, partition = %s, offset = %d, customer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value()); // (1)
  }
  
  try {
    consumer.commitSync(); // (2)
  } catch (CommitFailedEception e) {
    log.error("commit failed", e); // (3)
  }
}
```

1. Обработка записи состоит в выводе содержимого
2. После завершеия обработки всех записей текущего пакета вызываем `commitSync()` для фиксации последнего смещения
3. Метод `commitSync()` повторяет фиксацию до тех пор пока не возникнет непоправимая ошибка

#### 6. Асинхронная фиксация
Асинхронная фиксация в отличии от синхронной не блокирует основной поток.
Вместо того чтобы ждать ответа брокера на запрос фиксации, просто отправляем запрос и продолжаем работу

```java
Duration timeout = Duration.ofMillis(100);

while (true) {
  ConsumerRecods<String, String> records = consumer.poll(timeout);
  for (ConsumerRecord<String, String> record: records) {
      System.out.printf("topic = %s, partition = %s,
          offset = %d, customer = %s, country = %s\n",
          record.topic(), record.partition(), record.offset(),
          record.key(), record.value());
  }
  
  consumer.commitAsync(); // (1)
}
```
1. Фиксируем последнее смещение и продолжаем работу

Недостатки:
`commitSync()` будет повторять попытку фиксации до тех пор, пока она не завершится успешно или не возникнет ошибка, которую нельзя исправить путем повтора
`commitAsync()` повторять попыту не станет
    Причина этому то, что на момент получения ответа от сервера уже может быть успешно выполнена более поздняя фиксация

Функция обратного вызова
```java
Duration timeout = Duration.ofMillis(100);

while (true) {
  ConsumerRecods<String, String> records = consumer.poll(timeout);
  for (ConsumerRecord<String, String> record: records) {
      System.out.printf("topic = %s, partition = %s,
          offset = %d, customer = %s, country = %s\n",
          record.topic(), record.partition(), record.offset(),
          record.key(), record.value());
  }
  
  consumer.commitAsync(new OffsetCommitCallback() {
    public void onComplete(Map<TopicPartition,
      OffsetAndMetadata> offsets, Exception e) {
          if (e != null)
            log.error("Commit failed for offsets {}", offsets, e);
      }
  }); // (1)
}
```
1. Отправляем запрос на фиксацию и продолжаем работу, но в случае сбоя фиксации записываем в журнал информацию о себе и соответствующие смещения

#### 7. Сочетание синхронной и асинхронной фиксации
Если речь идет о последней фиксации перед закрытием потребителя и перебалнсировкой, то лчше позаботиться, чтобы она точно оказалась успешной

```java
Duration timeout = Duration.ofMillis(100);

try {
  while (!closing) {
      ConsumerRecords<String, String> records = consumer.poll(timeout);
      for (ConsumerRecord<String, String> record : records) {140  Глава 4. Потребители Kafka: чтение данных из Kafka
          System.out.printf("topic = %s, partition = %s, offset = %d,
              customer = %s, country = %s\n",
              record.topic(), record.partition(),
              record.offset(), record.key(), record.value());
      }
    consumer.commitAsync(); // (1)
  }
  
  consumer.commitSync(); // (2)
} catch (Exception e) {
  log.error("Unexpected error", e);
} finally {
  consumer.close();
}
```

1. Пока все нормально используем `commitAsync()`
2. При закрытии вызваем метод `commitSync()`, который станет повторять попытки вплоть до успещного выполнения или невосстановимого сбоя

#### 8. Фиксация заданного смещения
Если идет обработка пакета записей и смещение последнего полученного вами из раздела 3 в топике "покупатели" сообщения равно 5000
то можно вызвать метод `commitSync()` для фиксации смещения 5001 для раздела 3 в топике "покупатели"

```java
private Map<TopicPartition, OffsetAndMetadata> currentOffset = new HashMap<>; // (1)

int count = 0;

...

Duration timeout = Duration.ofMillis(100);
while (true){
  ConsumerRecords<String, String> records=consumer.poll(timeout);
  for (ConsumerRecord<String, String> record : records) {
      System.out.printf("topic = %s, partition = %s, offset = %d,
          customer = %s, country = %s\n",
          record.topic(), record.partition(), record.offset(),
          record.key(), record.value()); // (2)

      currentOffsets.put(
          new TopicPartition(record.topic(), record.partition()),
          new OffsetAndMetadata(record.offset()+1, "no metadata")); // (3)
      
      if (count % 1000 == 0) { // (4)
        consumer.commitAsync(currentOffsets, null); // (5)
      }
      
      count++;
  }
}
```

1. Ассоциативный словарь для отслеживания смещений вручную
2. Заглушка вместо реальной обработки записей
3. После чтения каждой записи обновляем словарь смещений, указывая смещение следующего намеченного для обработки сообщения.
   Зафиксированного смещение всегда должн быть сещением следующего сообщение, которое будет прочитано вашим приложением.
   Именно с этого места начинаем чтение в следующий раз
4. Фиксируем текущие смещения через каждые 1000 записей
5. Для фиксации можно вызвать как `commitAsync()` так и `commitSync()`


### 10. Прослушивание на предмет перебалансировки
Если известно, что раздел вот-вот перестанет принадлежать данному потребителю, то желательно зафиксировать смещения последних обработанных событий
А так же закрыть соеденинения с бд и т.д.

Для работы во время смены разедлов необходимо передавть объект `ConsumerRebalanceListener` при вызове метода `subscribe()`

`ConsumerRebalanceListener` имеет три доступных для реализации метода:
1. `public void onPartitionsAssigned(Collection<TopicPartition> partitions)` 
   вызывается после переназначения разделов потребителю, но до того как он начнет получать сообщения.
    Здесь можно подготовить и загрузить любое состояние, которое будет использоваться с разделом, находим правильное смещение если это необходимо
    Любая подготовка должна выполнится в течение `max.poll.timeout.ms`
2. `public void onPartitionsRevoke(Collection<TopicPartition> partitions)`
   вызывается, когда потребитель должен отказаться от разделов, которыми он ранее владел
   либо в результате перебалансировки
    либо при закрытии потребителя
    Метод вызывается до начала перебалансировки и после того, как потребитель перестал получать сообщения
    Если используется совместный алгоритм перебалансироки, метод вызывается в конце перебалансировки только с тем подмножеством разлделов, от которых потребитель должен отказаться
3. `public void onPartitionsLost(Collection partitions)`
   вызывается только при использовании совместного алгоритма перебалансировки и только в исключительных случаях
    когда разделы были назначены другим потребителям без предварительного отзыва алгоритмо перебалансировки
    Здесь очичаются все состояния или ресурсы, которые использовались с этими разделами


### 11. Особенности событий при совместной перебалансировке
1. Метод `onPartitionsAssigned()` будет вызываться при каждой перебалансировке. Если нет новых разделов, назанченных пользователю, он будет вызван с пустой коллекцией
2. Метод `onPartitionsRevoked()` будет вызываться в обычных условия пребалансировки, но только в том случае, если потребитель отказался от владения разделами 
3. Метод `onPartitionsLost()` будет вызываться в исключительных условиях перебалансировки, и к моменту его вызова у разделов в коллекции уже будут новые владельцы


### 12. Использование `onPartitionsRevoked()`
```java
private Map<TopicPartition, OffsetAndMetadata> currentOffsets = new HashMap<>;
Duration timeout = Suration.ofMills(100);

private class HandleRebalance implements ConsumerRebalanceListener { // (1)
  public void onPartitionsAssigned (Collection<TopicPartition> partitions) { // (2)
    
  }
  
  public void onPartitionsRevoked (Collection<TopicPartition> partitions) {
    System.out.println("Lost partitions in rebalance. Committing current offsets: " + currentOffsets);
    consumer.commitSync(currentOffsets); // (3)
  }
}

try {
  consumer.subscribe(topics, new HandleRebalance()); // (4)
 
  while (true) {
    ConsmerRecords<String, String> records = consumer.poll(timeout);
      
    for (ConsumerRecords<String, String> record: records) {
      System.out.printf("topic = %s, partition = $s, offset = %d, customer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());
      currentOffsets.put(
        new TopicPartition(record.topic(), record.partition()),
        new OffsetAndMetadata(record.offset() + 1, null)
      );
    }
    consumer.commitAsync(currentOffsets, null);
  }
} catch (WakeupException e) {
  // Игнорируем, посколько закрываемся
} catch (Exception e) {
  log.error("Unexpected error", e);
} finally {
  try {
    consumer.commitSync(currentOffsets);
  } finally {
    consimer.close();
    System.out.println("Closed consumer and we are done");
  }
}
```

1. Начинаем реализовывать класс `ConsumerRebalanceListener`
2. При назначении нового раздела не требуется ничего делать, просто читаем сообщение
3. Когда потребитель вот-вот потеряет раздел из-за перебалансировки, необходимо зафиксировать смещения
    Фиксируем смещения для всех разделов
4. Передаем `ConsumerRebalanceListener` в метод `subscribe()`

### 13. Получение записей с заданным смещением
Можно использовать для:
- Приложение, чувствительное ко времени, может пропустить вперед несколько записей, если оно отстает, или потребитель, 
    записывающий данные в файл может быть возвращен к определенному моменту времени, чтобы восстановить данные в случае потери файла

Пример:
```java
Long oneHourEarlier = Instant.now().atZone(ZoneId.systemDefault())
  .minusHours(1).toEpochSecond();
Map<TopicPartition, Long> partitionTimestampMap = consumer.assignment()
  .stream()
  .collect(Collectors.toMap(tp -> tp, tp -> oneHourEarlier)); // (1)
Map<TopicPartition, OffsetAndTimestamp> offsetMap = consumer.offsetsForTimes(partitionTimestampMap); // (2)

for (Map.Entry<TopicPartition, OffsetAndTimestamp> entry: offset.entrySet()) {
  consumer.seek(entry.getKey(), entry.getValue().offset()); // (3)
}
```

1. Мы создаем карту из всех разделов, назначенных этому потребителю (с помощью метода consumer.assignment()), до метки времени, к которой мы хотим вернуть потребители
2. Получаем смещения, которые были актуальны в этих временнх метках.
   Этот метод отправляет запрос брокеру, где индекс веменной метки используется для возврата соответствующих смещений
3. Сбрасываем смещения для каждого раздела на смещение, которое было возвращено на предыдущем шаге

### 14. Выход из цикла
`consumer.wakeup()` - единственный метод, потребителя, который можно безопасно вызывать из другого потока
Вызов `wakeup()` приведет к завершению выполнения метода poll() с генерацией искючения WakeupException
Если `consumer.wakeup()` был вызван в момент, когда поток не ожидает опроса, то исключение будет вызвано при вызове метода poll() во время следующей итерации
Обрабатывать исключение `WakeupException` не требуется, но перед завершением выполнение потока нужно вызвать consumer.close()

```java
Runtime.getRuntime().addShutdownHook(new Thread() {
  public void run() {
    System.out.println("Starting exist...");
    consumer.wakeup(); // (1)
    
    try {
      mainThread.join();
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
  }
})
  ...

Duration timeout = Duration.ofMills(10000); // (2)

try {
  // Выполняем цикл вплоть до нажатия Ctrl+C
  // об очистке при завершении выполнения
  // позаботится ShutdownHook
  
  while (true) {
    ConsumerRecords<String, String> records = movingAvg.consumer.poll(timeout);
    System.out.println(System.currentTimeMills() + "-- waiting for data...");
    
    for (ConsumerRecord<String, String> record: records) {
      System.out.printf("offset = %d, key = %s, value = %s\n", record.offset(), record.key(), record.value());
    }
    
    for (TopicPartition tp: consumer.assignment()) {
      System.out.println("Committing offset at position: " + consumer.position(tp));
      movingAvg.consumer.commitSync();
    }
  }
} catch (WakeupException e) {
  // Игнирируем (3)
} finally {
  consumer.close(); // (4)
  System.out.println("Closed consumer and we are done")
}
```

1. ShutdownHook работает в отдельном потоке, так что единственное что можно сделать безопасно - это вызвать `wakeup` для выхода их цикла `poll()`
2. Длительное время ожидания опроса. Если цикл опроса довольно короткий и можно немного подождать перед выходом, не нужно вызывать wakeup
    - достаточно просто проверять атомарное логическое значение на каждой итерации. 
   Длительное время ожидания опроса повезло при использовании топиков с низкой пропускной способностью 
    - таким образом клиент использует меньше ресурсов процессора для постанного зацикливания, пока брокер не получает новых данных для возврата
3. В результате вызова `wakeup` из другого потока `poll` сгенерирует исключение `WakeupException`. Его лучше перехватить, чтобы не произошло непредвиденного
   завершеия выполнения приложения, но ничего делать с этим не требуется
4. Перед завершением выполнения потребителя аккуратно закрываем его

### 15. Автономный потребитель
Когда заведомо один потребитель, которому нужно всегда читать данные из всех разделов топика или из его конкретного раздела
В таком случае достаточно назначить потребителю соотвествующие топик и/или разделы
Если точно известно, какие разделы должен читать потребитель, то не нужно "подписываться" на топик, а просто "назначить" себе несколко разделов

Пример:
```java
Duration timeout = Duration.offMills(100);
List<PartitionInfo> partitionInfos = null;
partitionInfos = consumer.partitionsFor("topic"); // (1)

if (partitionInfos != null) {
  for (Partitionnfo partition: partitionInfos) {
    partitions.add(new TopicPartition(partition.topic(), partition.partition()));
  }

  consumer.assign(partitions); // (2)
  
  while (true) {
    ConsumerRecords<String, String> records = consumer.poll(timeout);
    
    for (ConsumerRecords<String, String> record: recors) {
      System.out.printf("topic = %s, partiton = %s, offset = %d, customer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());
    }
    
    consumer.commitSync();
  }
}
```

1. Запрос у кластера доступных в данном топике разделов. Если есть конкретный раздел, то это можно пропустить
2. Вызываем метод `assing()` и передаем ему список

При добавлении в топик новых разделов потребитель об этом уведомлен не будет.
Об этом придется позаботится самостоятельно, переодически обращаясь к `consumer.partitionsFor()` или просто перезапуская приложение при добавлении разделов

## END ---------------- Потребитель ----------------

## AdminClient

+ [1. Применение AdminClient](#1-применение-adminclient)
+ [2. Особенности AdminClient](#2-особенности-adminclient)
+ [3. Опции методов](#3-опции-методов)
+ [4. Пример использования](#4-пример-использования)
+ [5. Управление основными топиками](#5-управление-основными-топиками)
+ [6. Управление конфигурацией](#6-управление-конфигурацией)
+ [7. Управление группами потребителей](#7-управление-группами-потребителей)
+ [8. Метаданные кластера](#8-метаданные-кластера)
+ [9. Расширенные операции администратора](#9-расширенные-операции-администратора)

### 1. Применение AdminClient
Используется при необходимости выполнить какие-то административные команды из клиенского приложения:
- Управление топиками - создание
- Управление группами потребителей
- Управление конфигурацией сущностей

### 2. Особенности AdminClient
- Является асинхронным - каждый метод возвращает один или несколько объектов Future
Например:
Kafka `AdminClient.createTopics` - возвращает `CreateTopicsResult`

### 3. Опции методов
Все методы по конфигурации имеют свой набор свойств для настройки
Единственное свойство, которое есть у всех методов - `timeoutMs` - определяет, как долго клиент будет ожидать завершения конфигурации, прежде чем выдать исключение `TimeoutException`

### 4. Пример использования
```java
Properties props = new Properties();
pops.put(AdmonClientConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
AdminClient admin = AdminClient.create(props);
// TODO: Do something useful with AdminClient
admin.close(Duration.ofSeconds(30));
```
Статический метод `create` принимает `Properties` в качестве параметра.
Единственным обязательным параметром является URI для кластера

При закрытии AdminClient некоторые опреации могут быть еще на стадии выполнения, поэтому метод `close` принимает параметр тайм-аута
После вызова `close` клиент будет ожидать завершения действий до окончания таймаута

### 5. Управление основными топиками
+ [1. Получение списка](#1-получение-списка)
+ [2. Проверить существует ли топик и создать новый если не существует](#2-проверить-существует-ли-топик-и-создать-новый-если-не-существует)
+ [3. Удаление топика](#3-удаление-топика)
+ [4. Множественное управление топиками с использованием KafkaFuture](#4-множественное-управление-топиками-с-использованием-kafkafuture)

#### 1. Получение списка

```java
ListTopicsResult topics = admin.listTopics();
topics.names().get().forEach(System.out::println);
```
ListTopicsResult - является тонкой оберткой над коллекцией Futures

#### 2. Проверить существует ли топик и создать новый если не существует
```java
DescribeTopicsResult demoTopic = amin.describeTopics(TOPIC_LIST); // (1)

try {
  topicDescription = demoTopic.values().get(TOPIC_NAME).get(); // (2)
  System.out.println("Description of demo topic:" + topicDescription);
  
  if (topicDescription.partitions.size() != NUM_PARTITIONS) { // (3)
    System.out.println("Topic has wrong number of partitions. Exiting.");
    System.exit(-1);
  }
} catch (ExecutionExceptio e) { // (4)
  // exit early for almost all exceptions
  if (! (e.getCause() instanceOf UnknownTopicOrPartitionException)) {
      e.printStackTrace();
      throw e;
  }

  // if we are here, topic doesn't exist
  System.out.println("Topic " + TOPIC_NAME + " does not exist. Going to create it now");

  // Note that number of partitions and replicas is optional. If they are
  // not specified, the defaults configured on the Kafka brokers will be used

  CreateTopicsResult newTopic = admin.createTopics(Collections.singletonList(new NewTopic(TOPIC_NAME, NUM_PARTITIONS, REP_FACTOR))); // (5)

  // Check that the topic was created correctly:
  if (newTopic.numPartitions(TOPIC_NAME).get() != NUM_PARTITIONS) { // (6)
      System.out.println("Topic has wrong number of partitions.");
      System.exit(-1);
  }
}
```

1. Чтобы проверить существует ли топик с правильной конфигурацией, вызваем `describeTopics()` со списком имен топиков, которые хотим проверить
2. Если топик не существует, то сервер ответит с ошибкой, а Future завершится выдачей исключения `ExecutionException`
3. Если топик существкет, Future завершается возвратом `TopicDescription`, который содержит список всех разделов топика, а для каждого раздела, в котором брокер является лидером 
   - список реплик и список синхронизованных реплик
4. Все объекты результатом выдают `ExecutionException`, когда Kafka отвечает с ошибкой
5. Если топик не существует, создаем новый
6. Дожидаемся результата создания топика и проверяем результат

#### 3. Удаление топика
````java
admin.deleteTopics(TOPIC_LIST).all().get();

// Check that it is gone. Note that due to the async nature of deletes,
// it is possible that at this point the topic still exists
try {
  topicDescription = demoTopic.values().get(TOPIC_NAME).get();
  System.out.println("Topic " + TOPIC_NAME + " is still around");
} catch (ExecutionException e) {
  System.out.println("Topic " + TOPIC_NAME + " is gone");
}
````

Note: Удаление топика - это безвозвратный процесс. Если удаляется не правильный топик, то вместе с ним все данные будут потеряны

#### 4. Множественное управление топиками с использованием KafkaFuture
```java
vertx.createHttpServer().requestHandler(request -> { // (1)
  String topic = request.getParam("topic"); // (2)
  String timeout = request.getParam("timeout");
  int timeoutMc = NumberUtils.toInt(timeout, 1000);
  DescribeTopicResult demoTopic = admin.describeTopics( // (3)
    Collections.singletonList(topic),
    new DescribeTopicOptions().timeoutMs(timeoutMs)
  );
  
  demoTopic.values().get(topic).whenComplete( // (4)
    new KafkaFuture.BiConsumer<TopicDescription, Throwable>() {
      @Override
      public void accept(final TopicDescription topicDescription, final Throwable throwable) {
        if (throwable != null) {
          request.response().end("Error trying to describe topic " + topic + " due to " + throwable.getMessage()); // (5)
        } else {
          request.response().end(topicDescription.toString()); // (6)
        } 
      } 
    }
  )
}).listen(8080);
```
1. Используем `Vert.x` для создания HTTP сервера. Каждый раз, когда сервер получет запрос, он вызывает `requestHandler`
2. Запрос включает в себя имя топика в качестве параметра
3. Вызываем `AdminClient.describeTopics` и получает ответ `Future`
4. Вместо использования блокирующего метода `get()` создаем функцию, которая будет вызвана, когда Future завершится
5. Если Future завершается с исключением, то отправляем ошибку клиенту
6. Если Future завершается успешно, отвечаем описанием топика

### 6. Управление конфигурацией

```java
ConfigResource configResource = new ConfigResurce(ConfigResource.Type.TOPIC, TOPIC_NAME); // (1)
DescribeConfigResult configResult = admin.describeConfigs(Collections.singleton(configResource));
Config config = configResult.all().get().get(configResourse);

// print nondefault configs
configs.entries().stream()
  .filter(entry -> !entry.isDefault())
  .forEach(System.out::println); // (2)

// Check if topic is compacted
ConfigEntry compaction = new ConfigEntry(TopicConfig.CLEANUP_POLICY_CONFIG, TopicConfig.CLEANUP_POLICY_COMPACT);

if (!config.entries().contains(compaction)) {
  // if topic is not compacted, compct it
  Collection<AlterConfigOp> configOp = new ArrayList<AlterConfigOp>();
  configOp.add(new AlterConfigOp(compaction, AlterConfigOp.OpType.SET)); // (3)
  Map<ConfigResource, Collection<AlterConfigOp>> alterConf = new HashMap<>();
  alterConf.put(configResource, configOp);
  admin.incrementalAlterConfigs(alterConf).all().get();
} else {
  System.out.println("Topic " + TOPIC_NAME + " is compacted topic");
}
```

1. В данном зпросе моно указать несколько ресурсов разных типов
2. Результатом `desctibeConfigs` является карта сопоставления каждого `ConfigResource` с коллекцией конфигурации. 
    Каждая запись конфигурации имеет метод `isDefault()`, который позволяет указать, какие конфигурации были изменены.
    Конфигурация топика считается не заанной по умолчанию
3. Чтобы изменить конфигурацию, укажите карту `ConfigResource`, который хотите изменить и наор операций
    Каждая операция по изменению конфигурации состоит из элемента конфигурации: `cleanup.policy` — это имя конфигурации, compacted — значение
    Существует 4 типа операций:
        - SET - установить
        - DELETE - удалить
        - APPEND - добавить
        - SUBSTRACT - вычесть


### 7. Управление группами потребителей

+ [1. Измение групп потребителей](#1-измение-групп-потребителей)
+ [2. Модификация групп потребителей](#2-модификация-групп-потребителей)

#### 1. Измение групп потребителей
- Составление списка потребителей
```java
admin.listCinsumerGroups().valid().get().forEach(System.out::println);
```
Будут возвращены только те группы отребителей, которые крастер вернул без ошибок

Если нужны дополнительная информация о некоторыз группах:
```java
ConsumerGroupDescription groupDescription = admin
  .describeConsumerGroups(CONSUMER_GRP_LIST)
  .describedGroups().get(CONSUMER_GROUP).get();
System.out.println("Description of group " + CONSUMER_GROUP + ":" + groupDescription);
```
В описание входит:
- члены группы, их идентификаторы и хосты
- назначенные им разделы
- алгоритм использованный для назначения
- хост координатора группы

Получение смещения:
```java
Map<TopicPartition, OffsetAndMetadata> offsets = admin.listConsumerGroupOffsets(CONSUMER_GROUP)
  .partitionsToOffsetAndMetadata().get(); // (1)

Map<TopPartition, OffsetSpec> requestLatestOffsets = new HashMap<>();

for (TopicPartition tp: offsets.keySet()) {
  requestLatestOffsets.put(tp, OssetsSpec.latest()); // (2)
}

Map<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo> laterstOffsets = admin.listOffsets(requestLatestOffsets).all().get();

for (Map.Entry<TopicPartition, OffsetAndMetadata> e: offsets.entrySet()) { // (3)
  String topic = e.getKey().topic();
  int partition = e.getKey().partition();
  long committedOffset = e.getValue().offset();
  long latestOffset = latestOffsets.get(e.getKey()).offset();

  System.out.println("Consumer group " + CONSUMER_GROUP
      + " has committed offset " + committedOffset
      + " to topic " + topic + " partition " + partition
      + ". The latest offset in the partition is "
      + latestOffset + " so consumer group is "
      + (latestOffset - committedOffset) + " records behind"
  );
}
```
1. Получаем карту всех топиков и разделов, которые обрабатывает группы потреьителей, и последнее зафиксированное смещение для каждой из них
2. Для каждого топика и раздела в результатах мы хотим получить смещение последнего сообщения в разделе.
    `OffsetSpec` имеет три удобные реализации: `earliest()`, `latest()` и `forTimestamp()`
3. Перебираем все разделы и для каждого из них выводим последнее зафиксированное смещение, последнее смещение в рзделе и задержку между ними

#### 2. Модификация групп потребителей
Задача: полностью перепроверить счет с 3:00
```java
Map<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo> earliestOffsets = admin.listOffsets(requestEarliestOffsets).all().get(); // (1)

Map<TopicPartition, OffsetAndMetadata> resetOffsets = new HashMap<>();
for (Map.Entry<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo> e: earliestOffsets.entrySet()) {
  resetOffsets.put(e.getKey(), new OffsetAndMetadata(e.getValue().offset())); // (2)
}

try {
  admin.alterConsumerGroupOffsets(CONSUMER_GROUP, resetOffsets).all().get(); // (3)
} catch (ExecutionException e) {
  System.out.println("Failed to update the offsets committed by group "
    + CONSUMER_GROUP + " with error " + e.getMessage()
  );
  if (e.getCause() instanceOf UnknownMemberIdException) {
  System.out.println("Check if consumer group is still active."); // (4)
  }
}
```
1. Чтобы сбросить группу потребителей и начать обработку с самого раннего смещения, нам нужно сначала получить самые ранние смещения
2. Преобразуем карту со значением `ListOffsetsResultInfo`, которые были возвращены `listOffsets`, в карту со значением `OffsetAndMetadata`, которые требуются для `alterConsumerGroupOffset`
3. После вызова `alterConumerGroupOffsets` мы ждем завершения работы Future
4. Распространенная причина сбоя `alterConsumerGroupOffsets` заключается в том, что мы сначала не остановили группу потребителей

### 8. Метаданные кластера
```java
DescribeClusterResult cluster = admin.describeCluster();

System.out.println("Connected to cluster " + cluster.clusterId().get()); // (1)
System.out.println("The brokers in the cluster are:");
cluster.nodes().get().forEach(node -> System.out.println(" * " + node));
System.out.println("The controller is: " + cluster.controller().get());
```
1. Идентификатор кластера представляет собой глобально уникальный идентификатор GUID и поэтому не читается человеком


### 9. Расширенные операции администратора

+ [1. Добавление разделов в топик](#1-добавление-разделов-в-топик)
+ [2. Удаление записей из топика](#2-удаление-записей-из-топика)
+ [3. Выборы лидера](#3-выборы-лидера)
+ [4. Переназнчение реплик](#4-переназнчение-реплик)


#### 1. Добавление разделов в топик

Можно добавить разделы в коллекцию топиков с помощью метода `creatPartitions`
```java
Map<String, NewPartitions> newPartitions = new HashMap<>();
newPartitions.put(TOPIC_NAME, NewPartitions.increaseTo(NUM_ARTITIONS + 2)); // (1)
admin.createPartitions(newPartitions).all().get();
```

1. При расширении топиков необходимо указать общее количество разделов, которое будет иметь топик после их добавления, а неколичество новых разделов

#### 2. Удаление записей из топика

Метод `deleteRecords` помечает как удаленные все записи со смещениями старше, чем указано при вызове метода и делает их недоступными для потребителей
```java
Map<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo> oldrOffsets = admin.listOffsets(requestOlderOffsets).all().get();
Map<TopicPartition, RecordsToDelete> recordsToDelete = new HashMap<>();

for (Map.Entry<TopicPartition, ListOffsetsResult.ListOffsetsResultInfo> e: olderOffsets.entrySet()) {
  recordsToDelete.put(e.getKey(), RecordsToDelete.beforeOffset(e.getValue().offset()));
}

admin.deleteRecords(recordsToDelete).all().get();
```

#### 3. Выборы лидера
Позволяет инициализировать два типа выборов лидера
- **Выборы предпочтительного лидера** - В каждом разделе есть реплика, которая назнаается предпочтительным лидером.
    По умолчанию Kafka каждые 5 минут будет проверять, действительно ли реплика предпочтиельного лидера является лидером, 
    и если это не так, но она имеет право стать лидером, то будет выбирать реплику предпочтительного лидера в качестве лидера.
    Если `auto.leader.rebalance.enable = false` можно запустить метод `electLeader()`
- **Выборы нечистого лидера** - Если ведущая реплика раздела становится недоступной, а другие реплики не имеют права становиться ведущими
    раздел остается без ведущей реплики. Один из способов решения проблемы - инициировать запуск выбора нечистого лидера,
    что означает избрание лидером реплики, которая в ином случае не имела бы права стать им

```java
Set<TopicPartition> electableTopics = new HashSet<>();
electableTopics.add(new TopicPartition(TOPIC_NAME, 0));

try {
  admin.electLeaders(ElectionType.PREFERRED, electableTopics).all().get(); // (1)
} catch (ExecutionException e) {
  if (e.getCause() instanceOf ElectionNotNeededException) {
    System.out.println("All leaders are preferred already"); // (2)
  }
}
```

1. Выбираем предпочтительного лидера в одном разделе конкретного топика. 
2. Есди кластер находится в исправом состоянии, команда ничего не сделает.
    Выборы как предпочтительного, так и нечистого лидера вступают в силу только в том случае, если текщим лидером является реплика, отличная от предпочтительного лидера

#### 4. Переназнчение реплик
Метод `lterPartitionReassignments` дает тонкий контроль над размещением каждой отдельной реплики для раздела

Пример:
Есть один брокер с идентификатором 0
Топик имеет несколько разделов, все с одной репликой на этом брокере
После добавления ного брокера мы хотим использовать его для хранения некоторых реплик топика
```java
Map<TopicPartition, Optional<NewPartitionReassignment>> reassignment = new HashMap<>();
reassignment.put(new TopicPartition(TOPIC_NAME, 0)), Optional.of(new NewPartitionReassignment(Arrays.asList(0 , 1))); // (1)
reassignment.put(new TopicPartition(TOPIC_NAME, 1)), Optional.of(new NewPartitionReassignment(Arrays.asList(1))); // (2)
reassignment.put(new TopicPartition(TOPIC_NAME, 2)), Optional.of(new NewPartitionReassignment(Arrays.asList(1, 0))); // (3)
reassignment.put(new TopicPartition(TOPIC_NAME, 3)), Optional.empty()); // (4)

admin.alterPartitionReassignments(reassignment).all().get();

System.out.println("currently reassigning: " + admin.listPartitionReassignments().reassingments().get()); // (5)
demoTopic = admin.describeTopics(TOPIC_LIST);
topicDescription = demoTopic.values().get(TOPIC_NAME).get();
System.out.println("Description of demo topic:" + topicDescription); // (6)
```

1. Добавляем одну реплику в раздел 0, размещаем новую реплику в брокер, который имеет идентификатор 1
2. Не добавляем никаких реплик в раздел 1 - просто перемещаем одну существующую реплику на новый брокер
3. Добавляем еще одну реплику в рзадел 2 и делае ее предпочтительным лидером
4. Для раздела 3 нет текущего переназначения
5. Перечисляем текущие переназначения
6. Выводим новое состояние

## END ---------------- AdminClient ----------------

## Внутреннее устройство

+ [1. Членство в кластере]()
+ [2. Контроллер]()
+ [3. Контроллер-лидер]()
+ [4. Репликации]()
+ [5. Обработка запросов]()

### 1. Членство в кластере
Для поддержания списка состоящих в настоящий момент в кластере брокеров используется Apache ZooKeeper
У каждого брокера есть уникальный идентификатор
При каждом запуске процесса брокер регистрируется с этим ID в ZooKeeper посредством создания временного узла
Брокеры Kaka, контроллер и некоторые инструменты экосистемы подписываются на путь регистрации брокеровЮ чтобы получать уведомления при добавлении или удалении брокеров

Если попробовать запусить второй брокер с тем же ID, будет возвращена ошибка

При потере связи брокера с ZooKeper созданный при запуске брокера временный узел будет удален автоматически
Подписанные на список брокеров компоненты будут уведомлены об удалении брокера

### 2. Контроллер
Контроллер - это брокер Kafka, который отвечает за выбор ведузих реплик для разделов
Первый запущенный в кластере брокер становится контроллеров, создавая в ZooKeeper временный узел под названием `/controller`

В случае останова брокера-контроллера или разрыва его соединения с ZooKeeper временный узел исчезнет
Когда временный узел исчезает, другие брокеры из кластера будут оповещены об этои и попытаются сами создать узел-контроллер
Первый кзел, создавший контроллер, становится следующим узлом-контроллером
Каждый вновь выбранный контроллер получает новое большее значение `номера эпохи контроллера`
Текущий `номера эпохи контроллера` известен брокерам, так что они будут игнорировать полученные от контроллера сообщения с более старым значением 

### 3. Контроллер-лидер
Когда контроллер впервые появляется, он должен получить последнюю карту состояния реплики из ZooKeeper, прежде чем сможет начать управлять метаданными кластера и выполнять работу лидера
Если контроллер обнаруживает, что брокер покинул кластер, то понимает, что всем разделам, ведущая реплика которых находилась на это брокере,
понадобится новая реплика
Он проходит по всем требующим новой ведущей реплики разделам, выбирает ее и отправляет запрос всем брокерам, создержащим новые или ведущие реплики, 
или существующие ведомые реплики для данных разделов
Сохраняет новое состояние в ZooKeeper а зачем отправляет запрос `LeaderAndISR` всем брокерам
Так же отправляет запрос на обновление метаданных

### 4. Репликации
Реплики хранятся на брокерах, причем каждый из них обычо хранит сотник или даже тысячи реплик, относящихся к разным топикам и разделам

2 типа реплик
- Ведущие - Одна реплика из каждого раздела назначается ведущей
    Через нее выполняются все запросы на генерацию, чтобы обеспечить согласованность
    Знает какие ведомые реплики актуальны по сравнению с ней. 
- Ведомые - все остальные реплики раздела
  Их основная задача реплицироваь сообщения от ведущей реплики и поддерживать актуальное состояние
  Если реплика не запрашивала сообщения более 10с или заправшивала, но не отстает более чем на 10с, то она считается `расогласованной`
  Если реплика стабильно запраштивает новые собщение, то она считается `согласованной`

### 5. Обработка запросов

+ [1. Структура заголовка запроса]()
+ [2. Потоки]()
+ [3. Типы клиенских запросов]()

#### 1. Структура заголовка запроса
- Тип запроса (Ключ API)
- версия запроса
- идентиикатор корреляции - число, уникальо идентифицирующее запрос и включаемое в твет и журналы ошибок
- идентификатор клиента - используется для идентифицкации отправившего запрос приложения

#### 2. Потоки
Для каждого порта, на котором брокер выполняет прослушивание, запускается
- принимающий поток (acceptor thread)  - создающий соединение и передающий контроль над ним `обрабатывающему потоку`
- обрабатывающий поток (processor thread)

#### 3. Типы клиенских запросов
- запросы от производителей - отправляются произодитлями и содержат сообщения, записываемые клиентами в брокер Kafka
- запросы на извлечение - отправляются потребителями и ведомыми репликами при чтении ими сообщений от брокеров
- запросы админимтратора - отправляются клиентами-администраторами при выполнении операций с метаданными

## END ---------------- Внутреннее устройство ----------------
