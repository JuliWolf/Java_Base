+ [Структура](#структура)
+ [Преимущества Kafka](#преимущества-kafka)
+ [Производитель](#производитель)


## Структура

+ [1. Сообщение и пакеты](#1-сообщение-и-пакеты)
+ [2. Топики и разделы](#2-топики-и-разделы)
+ [3. Производители и потребители](#3-производители-и-потребители)
+ [4. Брокеры и кластеры](#4-брокеры-и-кластеры)
+ [5. Несколько кластеров](#5-несколько-кластеров)


### 1. Сообщение и пакеты
Сообщение представляет собой массив байтов
Ключ - В сообщении может быть дополнитеьный фрагмет метаданных. Представляет собой тоже массив байтов
Ключи используются при необходимости лучше управлять записью сообщений в разделы и для сохранения порядка.
При передаче ключа, сообщение будет записано ровно в том порядке, в котором было передано.

Для эффективности сообщения записываются пакетами
Пакет (batch) представляет собой набор сообщений, относящихся к одному топику и разделу

### 2. Топики и разделы
Сообщения распределяются по топикам (topics)
Топики разбиваются на разделы (partitions)

Раздел представляет собой отдельный журнал
Сообщения записываются в него путем добавления в конец, а читаются по порядку от начала к концу

Любой из разделов можно разместить на отдельном сервере

### 3. Производители и потребители
Производители(producers) - генерируют новые сообщения. Производители сообщений создают их для конкретного топика. 
По умолчанию производитель будет равномерно поставлять сообщения во все разделы топика. 
В некоторых случаях он будет направлять сообщение в конкретный раздел. Для этого служат клют сообщения и объект Partitioner
Partitioner - генерирует хеш ключа и у станавливает его соотвестветствие с конкретным разделом. Это гарантирует запись всех сообщений с одиннаковым ключем в один и тот же раздел

Потребители(consumer) - читают сообщения.
Потребитель подписывается на один или более топиков и читает сообщения в корядке их создания в каждом разделе
Он ослеживает уже прочитанные сообщения, запоминая смещение сообщений
Смещение(offset) - непрерывно возрастающее целочисленное значение - элемент метаданных

Потребители работают в составе групп потребителей (consumer group) - одного или нескольких потребителей, объединенных для обработки топика
Организация в группы гарантирует чтение каждого раздела только одним членом группы.
Таким образом появляется возможность горизонтального масштабирования
В случае сбоя отдельного потребителя, оставшиеся члены группы переназначат потребляемые разделы

### 4. Брокеры и кластеры
Блокер(broker) - отдельный сервер Kafka
- Получает сообщения от производителей, присваивает им смещения и записывает в дисковое хранилище.
- Обслуживает потребителей и отвечает на запросы выборки из разделов, возвращая опубликованные сообщения

Блокеры предназначны для работы в составе _кластера_ (cluster)
Один из брокеров кластера функционрирует в качестве _контроллера_(cluster controller)
Контроллер кластера - выбираетсч автоматически из числа работающих членов кластера. 
    Отвечает за административные операции, включая распределение разделов по брокерам и мониторинг отказов брокеров

Каждый раздел принадлежи  одному из брокеров кластера, который называется ведущим (leader).
Реплицированный раздел можно назначить дополнительным брокерам, которые называются _последователями_(fillowers)
Все последователи полжны соединяться с ведущим для публикации сообщений
Потребители могут получать сообщения либо от ведущего, либо от одного из последователей

### 5. Несколько кластеров
Причины для нескольких кластеров:
- Разделение типов данных
- Изоляция по требованиям безопасности
- Несколько центров обработки данных (ЦОД)

Проект Kafka MirrorMaker позволяет реплицировать данные на другие кластера
Сообщения из двух локальных кластеров агрегируются в составной кластер, который затем копируется в другие ЦОД

## END ---------------- Структура ----------------

## Преимущества Kafka

+ [1. Несколько производителей](#1-несколько-производителей)
+ [2. Несколько потребителей](#2-несколько-потребителей)
+ [3. Сохранение информации на диске](#3-сохранение-информации-на-диске)
+ [4. Масштабируемость](#4-масштабируемость)
+ [5. Высокое быстродействие](#5-высокое-быстродействие)

### 1. Несколько производителей
Может работать с несколькими производителями, даже если они используют разные топики
Это позволяет агрегировать данные из множества клиенских систем и обеспечивает их согласованность

### 2. Несколько потребителей
Несколько потребителей могут читать любой одтин поток сообщений, не мешая друг другу

### 3. Сохранение информации на диске
Предполагает долговременное хранение данных и возможность чтение не в реальном времени
Правила хранения можно задать для каждого топика по отдельности

### 4. Масштабируемость
Благодаря горизонтальному масштабированию на каждом этапе структуры можно без проблем масштабировать в ходе развития системы

### 5. Высокое быстродействие
Благодаря схеме "Публикация/Подписка" получается отличная производительность при высокой нагрузке


## END ---------------- Преимущества Kafka ----------------

## Производитель

+ [1. Структура производителя](#1-структура-производителя)
+ [2. Обязательные свойства производителей](#2-обязательные-свойства-производителей)
+ [3. Пример создания нового производителя](#3-пример-создания-нового-производителя)
+ [4. Методы отправки сообщений](#4-методы-отправки-сообщений)
+ [5. Пример отправки сообщений](#5-пример-отправки-сообщений)
+ [6. Синхронная отправка сообщений](#6-синхронная-отправка-сообщений)
+ [7. Типы ошибок в KafkaProducer](#7-типы-ошибок-в-kafkaproducer)
+ [8. Асинхронная отправка сообщения](#8-асинхронная-отправка-сообщения)

### 1. Структура производителя
``````
                        ProducerRecord
                            Топик
  -------------------->    [Раздел]
 |         |                [Ключ]
 |         |                Значение
 |         |                    |
 В         |                    | send()
 случае    |                    V
 успех     |                Сериализатор
 возвращает|                    |
 метаданные|                    |
 |         |                    V
 |         |                Объект Partitioner
 |         |                |                    |
 |         |                |                    |
 |        Повторяем         V                    V
 |        попытку? ---> Топик А                Топик Б
 |         ^        да  Раздел 0               Раздел 1
 |         |            [Пакет 0]              [Пакет 0]
 |         |            [Пакет 1]              [Пакет 1]
 -----  Неудача?        [Пакет 2]              [Пакет 2]
           ^                        |
           |                        | 
           |                        V
           -------------------  Брокер Kafka
``````

1. Для генерации сообщений понадобится создать объект `ProducerRecord`, включающий топик, в который мы собираемся отправить запись и значение
2. Можно так же задать ключ и разде, временную метку и/или набор заголовков
3. После отправки происходит сериализация объекта ключа и значения в байтовые массивы для отправки по сети
4. Если разделы явно не указаны, данные попадают в объект `Partitioner`
5. Объект `Partitioner` выбирает раздел,  в соответствии с ключом из `ProducerRecord`
6. Если раздел выбран, то производитель будет знать в какой топик и раздел должна попасть запись
7. После запись помещается в пакет записей, предназначенных ддя отправки в топик и раздел
8. За отправку пакетов записей соответствующему брокеру Kafka отвечает отдельный поток выполнения
9. После получения сообщений брокер отправляет ответ
10. В случае успеха возвращается объект `RecordMetadata` содержащий топик, раздел и смещение записи в разделе
11. При неудаче будет возвращено сообщение об ошибке

### 2. Обязательные свойства производителей
- `bootstrap.servers` - список пар host:port брокеров, исользуемых производителем для первоначального соединения с кластером
  Производитель может получать дополнительную информацию после начального соединения. Рекомендуется включить хотя бы два брокера
- `key.serializer` - имя класса, применяемого для сериализации ключени записей, генерируемых для отправки в Kafka
  Значением должно быть имя класса, реализующего интерфейс `org.apache.kafka.common.serialization.Serializer` 
- `value.serializer` - имя класса, используемого для сериализации значений записей

### 3. Пример создания нового производителя
```java
Properties kafkaProps = new Properties(); // (1)
kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");

kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // (2)
kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); 

producer = new KafkaProducer<String, String>(kafkaProps);// (3)
```

1. Начинаем с объекта `Properties`
2. Мы планируем использовать строки для ключа и значения сообщения, поэтому подойдет `StringSerializer`
3. Создаем новый поизводитель, задавая подходящие типы ключа и значения и передавая в конструктор объект Properties

### 4. Методы отправки сообщений
1. Сделать и забыть - Отправляем сообщение на сервер, после чего особо не волнуемся дошло или нет
   В случае ошибок или таймауста сообщение будет потеряно и информации о потере не будет
2. Синхронная отправка - Производитель Kafka всгда асинхронный - метод send() возвращает объект класса Future
   Можно воспользоваться методом get() для ожидания ответа
3. Асинхронная отправка - вызываем send(), которому передается функция обратного вызова при получении ответа

### 5. Пример отправки сообщений
```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France"); // (1)

try {
  producer.send(record); // (2)
} catch (Exception e) {
  e.printStackTrace(); // (3)
}
```

1. Производитель получает на фходе объекты `ProducerRecord`, поэтому начинаем с создания самого объекта
   Используется конструктор, принимающий на входе - название топика, ключ и значение
2. Для отправки используется метод send(), который возвращает объект класса Future
3. Выводит потенциальные ошибки

### 6. Синхронная отправка сообщений
При синхронной отправке тратится время на ожидаение ответа и блокируется весь поток выполнения
```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");

try {
  producer.send(record).get(); // (1)
} catch (Exception e) {
  e.printStackTrace(); // (2)
}
```

1. Используется метод Future.get() для ожидания ответа от Kafka
   Метод генерирует исключение в случае неудачи отправки записи.
    При отсутствии ошибок мы получим объект `RecordMetadata`
2. Если перед отправкой или во время отправки записи возникли ошибки, то мы получим исключение и выведем информацию о нем

### 7. Типы ошибок в KafkaProducer
1. Ошибки, которые можно исправить, отправив сообщение повторно (repitable)
   Например, ошибка соединения, ошибка "отсутствует ведущий узел для раздела"
2. Ошибки, которые невозможно исправить
    Например, "сообщение слишком велико"

### 8. Асинхронная отправка сообщения
Для асихронной отправки сообщений с сохранением возможности обработки различных сценариев ошибок производителя поддерживают функции обратного вызова при оправке записи

```java
private class DemoProducerCallback implements Callback { // (1)
  @Override
  public void onComletion (RecordMetadata recordMetadata, Exception e) {
    if (e != null) {
      e.printStackTrace(); // (2)
    }
  }
}

ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Biomedical Materials", "USA"); // (3)
producer.send(record, new DemoProducerCallback()); // (4)
```

1. Для использования функций обратного вызов понадобится класс, реализующий интерфейс `org.apache.kafka.clients.producer.Callback`
2. Если Kafka вернет ошибку, в функцию `onCompetion()` попадет непустое исключение
3. Записи остаются такими же как и при синхронном вызове
4. Передаем Callback при отправке записи

## END ---------------- Производитель ----------------