+ [Структура](#структура)
+ [Преимущества Kafka](#преимущества-kafka)
+ [Производитель](#производитель)
+ [Потребитель](#потребитель)

## Структура

+ [1. Сообщение и пакеты](#1-сообщение-и-пакеты)
+ [2. Топики и разделы](#2-топики-и-разделы)
+ [3. Производители и потребители](#3-производители-и-потребители)
+ [4. Брокеры и кластеры](#4-брокеры-и-кластеры)
+ [5. Несколько кластеров](#5-несколько-кластеров)


### 1. Сообщение и пакеты
Сообщение представляет собой массив байтов. Представляет собой пару ключ/значение

Ключ - В сообщении может быть дополнитеьный фрагмет метаданных. Представляет собой тоже массив байтов
Ключи используются при необходимости лучше управлять записью сообщений в разделы и для сохранения порядка.
При передаче ключа, сообщение будет записано ровно в том порядке, в котором было передано.
Все сообщения с одиннаковым ключем попадут в один раздел. Это значит, если каждый процесс читает лишь часть разделов топика, все записи для конкретного ключа будет читать один и тот же процесс

Для эффективности сообщения записываются пакетами
Пакет (batch) представляет собой набор сообщений, относящихся к одному топику и разделу

### 2. Топики и разделы
Сообщения распределяются по топикам (topics)
Топики разбиваются на разделы (partitions)

Раздел представляет собой отдельный журнал
Сообщения записываются в него путем добавления в конец, а читаются по порядку от начала к концу

Любой из разделов можно разместить на отдельном сервере

### 3. Производители и потребители
Производители(producers) - генерируют новые сообщения. Производители сообщений создают их для конкретного топика. 
По умолчанию производитель будет равномерно поставлять сообщения во все разделы топика. 
В некоторых случаях он будет направлять сообщение в конкретный раздел. Для этого служат клют сообщения и объект Partitioner
Partitioner - генерирует хеш ключа и у станавливает его соотвестветствие с конкретным разделом. Это гарантирует запись всех сообщений с одиннаковым ключем в один и тот же раздел

Потребители(consumer) - читают сообщения.
Потребитель подписывается на один или более топиков и читает сообщения в корядке их создания в каждом разделе
Он ослеживает уже прочитанные сообщения, запоминая смещение сообщений
Смещение(offset) - непрерывно возрастающее целочисленное значение - элемент метаданных

Потребители работают в составе групп потребителей (consumer group) - одного или нескольких потребителей, объединенных для обработки топика
Организация в группы гарантирует чтение каждого раздела только одним членом группы.
Таким образом появляется возможность горизонтального масштабирования
В случае сбоя отдельного потребителя, оставшиеся члены группы переназначат потребляемые разделы

### 4. Брокеры и кластеры
Блокер(broker) - отдельный сервер Kafka
- Получает сообщения от производителей, присваивает им смещения и записывает в дисковое хранилище.
- Обслуживает потребителей и отвечает на запросы выборки из разделов, возвращая опубликованные сообщения

Блокеры предназначны для работы в составе _кластера_ (cluster)
Один из брокеров кластера функционрирует в качестве _контроллера_(cluster controller)
Контроллер кластера - выбираетсч автоматически из числа работающих членов кластера. 
    Отвечает за административные операции, включая распределение разделов по брокерам и мониторинг отказов брокеров

Каждый раздел принадлежи  одному из брокеров кластера, который называется ведущим (leader).
Реплицированный раздел можно назначить дополнительным брокерам, которые называются _последователями_(fillowers)
Все последователи полжны соединяться с ведущим для публикации сообщений
Потребители могут получать сообщения либо от ведущего, либо от одного из последователей

### 5. Несколько кластеров
Причины для нескольких кластеров:
- Разделение типов данных
- Изоляция по требованиям безопасности
- Несколько центров обработки данных (ЦОД)

Проект Kafka MirrorMaker позволяет реплицировать данные на другие кластера
Сообщения из двух локальных кластеров агрегируются в составной кластер, который затем копируется в другие ЦОД

## END ---------------- Структура ----------------

## Преимущества Kafka

+ [1. Несколько производителей](#1-несколько-производителей)
+ [2. Несколько потребителей](#2-несколько-потребителей)
+ [3. Сохранение информации на диске](#3-сохранение-информации-на-диске)
+ [4. Масштабируемость](#4-масштабируемость)
+ [5. Высокое быстродействие](#5-высокое-быстродействие)

### 1. Несколько производителей
Может работать с несколькими производителями, даже если они используют разные топики
Это позволяет агрегировать данные из множества клиенских систем и обеспечивает их согласованность

### 2. Несколько потребителей
Несколько потребителей могут читать любой одтин поток сообщений, не мешая друг другу

### 3. Сохранение информации на диске
Предполагает долговременное хранение данных и возможность чтение не в реальном времени
Правила хранения можно задать для каждого топика по отдельности

### 4. Масштабируемость
Благодаря горизонтальному масштабированию на каждом этапе структуры можно без проблем масштабировать в ходе развития системы

### 5. Высокое быстродействие
Благодаря схеме "Публикация/Подписка" получается отличная производительность при высокой нагрузке


## END ---------------- Преимущества Kafka ----------------

## Производитель

+ [1. Структура производителя](#1-структура-производителя)
+ [2. Обязательные свойства производителей](#2-обязательные-свойства-производителей)
+ [3. Пример создания нового производителя](#3-пример-создания-нового-производителя)
+ [4. Методы отправки сообщений](#4-методы-отправки-сообщений)
+ [5. Пример отправки сообщений](#5-пример-отправки-сообщений)
+ [6. Синхронная отправка сообщений](#6-синхронная-отправка-сообщений)
+ [7. Типы ошибок в KafkaProducer](#7-типы-ошибок-в-kafkaproducer)
+ [8. Асинхронная отправка сообщения](#8-асинхронная-отправка-сообщения)
+ [9. Разделы](#9-разделы)
+ [10. Заголовки](#10-заголовки)
+ [11. Перехватчики](#11-перехватчики)

### 1. Структура производителя
``````
                        ProducerRecord
                            Топик
  -------------------->    [Раздел]
 |         |                [Ключ]
 |         |                Значение
 |         |                    |
 В         |                    | send()
 случае    |                    V
 успех     |                Сериализатор
 возвращает|                    |
 метаданные|                    |
 |         |                    V
 |         |                Объект Partitioner
 |         |                |                    |
 |         |                |                    |
 |        Повторяем         V                    V
 |        попытку? ---> Топик А                Топик Б
 |         ^        да  Раздел 0               Раздел 1
 |         |            [Пакет 0]              [Пакет 0]
 |         |            [Пакет 1]              [Пакет 1]
 -----  Неудача?        [Пакет 2]              [Пакет 2]
           ^                        |
           |                        | 
           |                        V
           -------------------  Брокер Kafka
``````

1. Для генерации сообщений понадобится создать объект `ProducerRecord`, включающий топик, в который мы собираемся отправить запись и значение
2. Можно так же задать ключ и разде, временную метку и/или набор заголовков
3. После отправки происходит сериализация объекта ключа и значения в байтовые массивы для отправки по сети
4. Если разделы явно не указаны, данные попадают в объект `Partitioner`
5. Объект `Partitioner` выбирает раздел,  в соответствии с ключом из `ProducerRecord`
6. Если раздел выбран, то производитель будет знать в какой топик и раздел должна попасть запись
7. После запись помещается в пакет записей, предназначенных ддя отправки в топик и раздел
8. За отправку пакетов записей соответствующему брокеру Kafka отвечает отдельный поток выполнения
9. После получения сообщений брокер отправляет ответ
10. В случае успеха возвращается объект `RecordMetadata` содержащий топик, раздел и смещение записи в разделе
11. При неудаче будет возвращено сообщение об ошибке

### 2. Обязательные свойства производителей
- `bootstrap.servers` - список пар host:port брокеров, исользуемых производителем для первоначального соединения с кластером
  Производитель может получать дополнительную информацию после начального соединения. Рекомендуется включить хотя бы два брокера
- `key.serializer` - имя класса, применяемого для сериализации ключени записей, генерируемых для отправки в Kafka
  Значением должно быть имя класса, реализующего интерфейс `org.apache.kafka.common.serialization.Serializer` 
- `value.serializer` - имя класса, используемого для сериализации значений записей

### 3. Пример создания нового производителя
```java
Properties kafkaProps = new Properties(); // (1)
kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");

kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // (2)
kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); 

producer = new KafkaProducer<String, String>(kafkaProps);// (3)
```

1. Начинаем с объекта `Properties`
2. Мы планируем использовать строки для ключа и значения сообщения, поэтому подойдет `StringSerializer`
3. Создаем новый поизводитель, задавая подходящие типы ключа и значения и передавая в конструктор объект Properties

### 4. Методы отправки сообщений
1. Сделать и забыть - Отправляем сообщение на сервер, после чего особо не волнуемся дошло или нет
   В случае ошибок или таймауста сообщение будет потеряно и информации о потере не будет
2. Синхронная отправка - Производитель Kafka всгда асинхронный - метод send() возвращает объект класса Future
   Можно воспользоваться методом get() для ожидания ответа
3. Асинхронная отправка - вызываем send(), которому передается функция обратного вызова при получении ответа

### 5. Пример отправки сообщений
```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France"); // (1)

try {
  producer.send(record); // (2)
} catch (Exception e) {
  e.printStackTrace(); // (3)
}
```

1. Производитель получает на фходе объекты `ProducerRecord`, поэтому начинаем с создания самого объекта
   Используется конструктор, принимающий на входе - название топика, ключ и значение
2. Для отправки используется метод send(), который возвращает объект класса Future
3. Выводит потенциальные ошибки

### 6. Синхронная отправка сообщений
При синхронной отправке тратится время на ожидаение ответа и блокируется весь поток выполнения
```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");

try {
  producer.send(record).get(); // (1)
} catch (Exception e) {
  e.printStackTrace(); // (2)
}
```

1. Используется метод Future.get() для ожидания ответа от Kafka
   Метод генерирует исключение в случае неудачи отправки записи.
    При отсутствии ошибок мы получим объект `RecordMetadata`
2. Если перед отправкой или во время отправки записи возникли ошибки, то мы получим исключение и выведем информацию о нем

### 7. Типы ошибок в KafkaProducer
1. Ошибки, которые можно исправить, отправив сообщение повторно (repitable)
   Например, ошибка соединения, ошибка "отсутствует ведущий узел для раздела"
2. Ошибки, которые невозможно исправить
    Например, "сообщение слишком велико"

### 8. Асинхронная отправка сообщения
Для асихронной отправки сообщений с сохранением возможности обработки различных сценариев ошибок производителя поддерживают функции обратного вызова при оправке записи

```java
private class DemoProducerCallback implements Callback { // (1)
  @Override
  public void onComletion (RecordMetadata recordMetadata, Exception e) {
    if (e != null) {
      e.printStackTrace(); // (2)
    }
  }
}

ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Biomedical Materials", "USA"); // (3)
producer.send(record, new DemoProducerCallback()); // (4)
```

1. Для использования функций обратного вызов понадобится класс, реализующий интерфейс `org.apache.kafka.clients.producer.Callback`
2. Если Kafka вернет ошибку, в функцию `onCompetion()` попадет непустое исключение
3. Записи остаются такими же как и при синхронном вызове
4. Передаем Callback при отправке записи

### 9. Разделы

+ [1. Зачем нужны разделы](#1-зачем-нужны-разделы)
+ [2. Пример создания сообщения с ключем](#2-пример-создания-сообщения-с-ключем)
+ [3. Что используется для балансировки сообщений](#3-что-используется-для-балансировки-сообщений)
+ [4. Реализация Partitioner](#4-реализация-partitioner)

#### 1. Зачем нужны разделы
1. Каждый топик может иметь 1 или больше разделов, которые распределяются по разным узлам кластера (брокерам)
Это позволяет нескольким потребителям считывать данные из одного топика одновременно
2. Если число потребителей меньше числа разделов, один consumer получает сообщения из нескольких разделов
3. Если потребителей больше, чем разделов, нескоторые consumer не получат никаких сообщений, пока общее количество потребителей не снизится до количества разделов
4. На пратике максимальное число разделов ограничивается размером сохраняемых сообщений, которые могут поместиться на одном узле
   Теоретически максимальное количество разделов может быть любым
5. Чтобы повысить надежность и доступность данных в кластере Kafka, разедлы могут иметь копии
6. Число разделов и коэффициент репликации можно настроить для всего класеа или для кадого топика отдельно


#### 2. Пример создания сообщения с ключем
```java
ProducerRecord<String String> record = new ProducerRecord<>("CustomerCountry", "Labratory Equipment", "USA")
```
без ключа
```java
ProducerRecord<String String> record = new ProducerRecord<>("CustomerCountry", "USA")
```

#### 3. Что используется для балансировки сообщений
Если ключ не указан, то запись будет отправлена в один из доступных рахделов топика случайным образом
Для балансировки сообщений по разделам будет применяться циклический алгорит (round-robin)
Начиная с весрии 2.4 циклический алгоритм является "липким". Это означает, что он будет заполнять пакет сообщений, отправленных в один раздел, прежде чем переключиться на следующий.

Если ключ указан, то будет вычислено хеш-значение с помощью собственного алгоритма хеширования, так что хеш-значение не изменяется при обновлении Java

#### 4. Реализация Partitioner
```java
import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.record.InvalidRecordException;
import org.apache.kafka.common.utils.Utils;

public class BananaPartitioner implements Partitioner {
  public void configure (Map<String, ?> configs) {} // 1()
  
  public int partition (String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
    int numPartitions = partitions.size();
    
    if ((keyBytes == null) || (!(ky instanceof String))) { // (2)
      throw new InvalidRecordException("We expect all messages to have customer name as key");
    }
    
    if ((String) key.equals("Banana")) {
      return numPartitions - 1; // Banana всегда попадает в последний раздел
    }
    
    // Другие записи рспределяются по разделам хеширования
    return Math.abs(this.murmur(keyBytes)) % (numPartitions - 1);
  }
}
```

1. Интерфейс объекта секционирования включает методы configure, partition и close.
2. Мы ожидаем только токовые ключи, иначе генерируем исключение

### 10. Заголовки

Записи могут включать в себя заголовки.
Заголовки могут содержать некоторые метаданные о записи
Используются например для указания источника данных в записи, а также для маршрутизации или отслеживания сообщений на основе информации заголовка

Представлены в виде коллекции "ключ/значение".
Ключи всегда являются строками, а значениями могут быть любые сериализованные объекты

```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");

record.headers().add("privacy-level","YOLO".getBytes(StandardCharsets.UTF_8));
```

### 11. Перехватчики

Перехватчики используются для измененияповедения клиенского приложения, без изменения кода

ProducerInterceptop включают два ключевых метода:
- ProducerRecord<K, V> onSend(ProducerRecord<K, V> record) - метод будет вызван до того, как созданная запись будет отправлена.
    Переобпределяя метод можно получить информацию об отправленной записи и даже изменить ее
- void onAcknowledgement(RecordMetadata metadata, Exception exception) - метод будет вызван, если и когда ответит подтверждением на автоотправку

Примеры использования:
- Сбор информации для мониторинга и отслеживания
- Дополнение сообщения стандартными заголовками
- Редактирование конфиденциальной информации

Пример:
```java
public class CountingProducerIntercepor implements ProducerInterceptor {
  ScheduledExecutorService executorService = Executors.newSingleThreadScheduledExecutor();
  static AtomicLong numSent = new AtomicLong(0);
  static AtomicLong numAcked = new AtomicLong(0);

  public void configure(Map<String, ?> map) {
    Long windowSize = Long.valueOf((String) map.get("counting.interceptor.window.size.ms")); // (1)
    executorService.scheduleAtFixedRate(CountingProducerInterceptor::run, windowSize, windowSize, TimeUnit.MILLISECONDS);
  }

  public ProducerRecord onSend(ProducerRecord producerRecord) {
    numSent.incrementAndGet();
    return producerRecord; // (2)
  }

  public void onAcknowledgement(RecordMetadata recordMetadata, Exception e) {
    numAcked.incrementAndGet(); // (3)
  }
  
  public void close() {
    executorService.shutdownNow(); // (4)
  }
  
  public static void run() {
    System.out.println(numSent.getAndSet(0));
    System.out.println(numAcked.getAndSet(0));
  }
}
```

1. ProducerInterceptor - это настраиваемый интерфейс. Можно переопределить метод confgure и выполнить настройку перед вызовом любого другого метода
2. Когда запись отправлена, увеличиваем счетчик записей и возвращаем запись
3. Когда Kafka отвечает подтверждением получения, увеличивем счетчик подтверждений и не должны ничего возвращать
4. Метод вызывается когда производитель закрывается. В данном случае мы закрываем открытый поток. 

## END ---------------- Производитель ----------------

## Потребитель

+ [1. Группа потребителей](#1-группа-потребителей)
+ [2. Способы масштабирования](#2-способы-масштабирования)
+ [3. Как происходит перебалансировка разделов](#3-как-происходит-перебалансировка-разделов)
+ [4. Как потребители поддерживают членство в группе](#4-как-потребители-поддерживают-членство-в-группе)
+ [5. Что происходит когда потребители присоединяются к группу](#5-что-происходит-когда-потребители-присоединяются-к-группу)

### 1. Группа потребителей
Если несколько потребителей подписаны на один топик и относятся к одной группе, все они будут получать сообщения из различных подмножеств разделов группы

Пример:
Топик Т1 с 4мя разделами
    - Раздел 0
    - Раздел 1
    - Раздел 2
    - Раздел 3

Потребитель C1 - единственный потребитель в группе G1 и подписан на топик T1

Если мы добавим в G1 еще один потребитель C2
    то каждый потребитель будет получать сообщения только из двух разделов

Если в группе G1 будет 4 потребителя, то каждый из них будет читать сообщения из своего раздела

T1                        G1
- Раздел 0   ---->   - Потребитель 1
- Раздел 1   ---->   - Потребитель 2
- Раздел 2   ---->   - Потребитель 3
- Раздел 3   ---->   - Потребитель 4

Если же потребителей в группе G1 будет больше чем разделов в топике, то потребители часто будут простаивать и вообще не получать сообщения

### 2. Способы масштабирования
Чаще всего потребители выполняют операции с высокой задержкой, т.е. потребитель будет отставать от темпов поступления данных в топик
Основной метод масштабировани - добавление новых потребителей, каждый из которых отвечает лишь за часть разделов и сообщений

### 3. Как происходит перебалансировка разделов
Перебалансировка - передача раздела от одного потребителя другому
- Добавленный в группу потребитель начинает получать сообщения из разделов, за которые ранее отвечал другой потребитель
- То же самое происходит если потребитель останавливается или аварийно завершается
- Переназначение разделов потребителям происходит также при изменении топиков

Типы перебалансировки:
1. Безотлагательная перебалансировка - Все потребители прекращают потребление, отказываются от своих прав владения всеми разделами
   снова присоединяются к группе потребителей и получают совершенно новое назначение разделов
2. Совместная перебалансировка (инкрементная перебалансировка) - переназначение лишь небольшого подмножества разделов от одного потребителя к другому
    и позволяет потребителям продожать обработку записей из всех разделов, которые не были переназначены
    - Сначала лидер группы потребителей собщает всем потребителям, что они потеют право владения подмножеством свих разделов
    - Потребители прекращают потребление из этих разделов
    - Отказывается от своего права владния ими
    - Лидер назначает эти осиротевшие разделы их новым владельцам

### 4. Как потребители поддерживают членство в группе
Потребители отправляют назначенному координатором группы брокеру Kafka переодических контрольных сигналов (heartbeats)
Если потребитель длительное время не отправляет сигналы, время его сеанса истекает, координатор группы признает его неработающим и инициирует перебалансировку

### 5. Что происходит когда потребители присоединяются к группу
- Потребитель отправляет сигнал координатору группы запрос JoinGroup
- Первый присоединившийся к группе потребитель становится ведущим потребителем группы
- Ведущий потребитель группы получает от координатора список всех потребителей, которые недавно отправляли контрольные сигналы
- Для определения того, за какие разделы какой потребитель должен отвечать, используется реализация класса PartitionAssignor
- Происходит распределение разделов
- После распределения разделов лидер группы потребителей отправляет список назначений координатору группы, которые пересылает информацию потребителям

## END ---------------- Потребитель ----------------