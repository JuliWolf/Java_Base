+ [Структура](#структура)
+ [Преимущества Kafka](#преимущества-kafka)
+ [Производитель](#производитель)
+ [Потребитель](#потребитель)

## Структура

+ [1. Сообщение и пакеты](#1-сообщение-и-пакеты)
+ [2. Топики и разделы](#2-топики-и-разделы)
+ [3. Производители и потребители](#3-производители-и-потребители)
+ [4. Брокеры и кластеры](#4-брокеры-и-кластеры)
+ [5. Несколько кластеров](#5-несколько-кластеров)


### 1. Сообщение и пакеты
Сообщение представляет собой массив байтов. Представляет собой пару ключ/значение

Ключ - В сообщении может быть дополнитеьный фрагмет метаданных. Представляет собой тоже массив байтов
Ключи используются при необходимости лучше управлять записью сообщений в разделы и для сохранения порядка.
При передаче ключа, сообщение будет записано ровно в том порядке, в котором было передано.
Все сообщения с одиннаковым ключем попадут в один раздел. Это значит, если каждый процесс читает лишь часть разделов топика, все записи для конкретного ключа будет читать один и тот же процесс

Для эффективности сообщения записываются пакетами
Пакет (batch) представляет собой набор сообщений, относящихся к одному топику и разделу

### 2. Топики и разделы
Сообщения распределяются по топикам (topics)
Топики разбиваются на разделы (partitions)

Раздел представляет собой отдельный журнал
Сообщения записываются в него путем добавления в конец, а читаются по порядку от начала к концу

Любой из разделов можно разместить на отдельном сервере

### 3. Производители и потребители
Производители(producers) - генерируют новые сообщения. Производители сообщений создают их для конкретного топика. 
По умолчанию производитель будет равномерно поставлять сообщения во все разделы топика. 
В некоторых случаях он будет направлять сообщение в конкретный раздел. Для этого служат клют сообщения и объект Partitioner
Partitioner - генерирует хеш ключа и у станавливает его соотвестветствие с конкретным разделом. Это гарантирует запись всех сообщений с одиннаковым ключем в один и тот же раздел

Потребители(consumer) - читают сообщения.
Потребитель подписывается на один или более топиков и читает сообщения в корядке их создания в каждом разделе
Он ослеживает уже прочитанные сообщения, запоминая смещение сообщений
Смещение(offset) - непрерывно возрастающее целочисленное значение - элемент метаданных

Потребители работают в составе групп потребителей (consumer group) - одного или нескольких потребителей, объединенных для обработки топика
Организация в группы гарантирует чтение каждого раздела только одним членом группы.
Таким образом появляется возможность горизонтального масштабирования
В случае сбоя отдельного потребителя, оставшиеся члены группы переназначат потребляемые разделы

### 4. Брокеры и кластеры
Блокер(broker) - отдельный сервер Kafka
- Получает сообщения от производителей, присваивает им смещения и записывает в дисковое хранилище.
- Обслуживает потребителей и отвечает на запросы выборки из разделов, возвращая опубликованные сообщения

Блокеры предназначны для работы в составе _кластера_ (cluster)
Один из брокеров кластера функционрирует в качестве _контроллера_(cluster controller)
Контроллер кластера - выбираетсч автоматически из числа работающих членов кластера. 
    Отвечает за административные операции, включая распределение разделов по брокерам и мониторинг отказов брокеров

Каждый раздел принадлежи  одному из брокеров кластера, который называется ведущим (leader).
Реплицированный раздел можно назначить дополнительным брокерам, которые называются _последователями_(fillowers)
Все последователи полжны соединяться с ведущим для публикации сообщений
Потребители могут получать сообщения либо от ведущего, либо от одного из последователей

### 5. Несколько кластеров
Причины для нескольких кластеров:
- Разделение типов данных
- Изоляция по требованиям безопасности
- Несколько центров обработки данных (ЦОД)

Проект Kafka MirrorMaker позволяет реплицировать данные на другие кластера
Сообщения из двух локальных кластеров агрегируются в составной кластер, который затем копируется в другие ЦОД

## END ---------------- Структура ----------------

## Преимущества Kafka

+ [1. Несколько производителей](#1-несколько-производителей)
+ [2. Несколько потребителей](#2-несколько-потребителей)
+ [3. Сохранение информации на диске](#3-сохранение-информации-на-диске)
+ [4. Масштабируемость](#4-масштабируемость)
+ [5. Высокое быстродействие](#5-высокое-быстродействие)

### 1. Несколько производителей
Может работать с несколькими производителями, даже если они используют разные топики
Это позволяет агрегировать данные из множества клиенских систем и обеспечивает их согласованность

### 2. Несколько потребителей
Несколько потребителей могут читать любой одтин поток сообщений, не мешая друг другу

### 3. Сохранение информации на диске
Предполагает долговременное хранение данных и возможность чтение не в реальном времени
Правила хранения можно задать для каждого топика по отдельности

### 4. Масштабируемость
Благодаря горизонтальному масштабированию на каждом этапе структуры можно без проблем масштабировать в ходе развития системы

### 5. Высокое быстродействие
Благодаря схеме "Публикация/Подписка" получается отличная производительность при высокой нагрузке


## END ---------------- Преимущества Kafka ----------------

## Производитель

+ [1. Структура производителя](#1-структура-производителя)
+ [2. Обязательные свойства производителей](#2-обязательные-свойства-производителей)
+ [3. Пример создания нового производителя](#3-пример-создания-нового-производителя)
+ [4. Методы отправки сообщений](#4-методы-отправки-сообщений)
+ [5. Пример отправки сообщений](#5-пример-отправки-сообщений)
+ [6. Синхронная отправка сообщений](#6-синхронная-отправка-сообщений)
+ [7. Типы ошибок в KafkaProducer](#7-типы-ошибок-в-kafkaproducer)
+ [8. Асинхронная отправка сообщения](#8-асинхронная-отправка-сообщения)
+ [9. Разделы](#9-разделы)
+ [10. Заголовки](#10-заголовки)
+ [11. Перехватчики](#11-перехватчики)

### 1. Структура производителя
``````
                        ProducerRecord
                            Топик
  -------------------->    [Раздел]
 |         |                [Ключ]
 |         |                Значение
 |         |                    |
 В         |                    | send()
 случае    |                    V
 успех     |                Сериализатор
 возвращает|                    |
 метаданные|                    |
 |         |                    V
 |         |                Объект Partitioner
 |         |                |                    |
 |         |                |                    |
 |        Повторяем         V                    V
 |        попытку? ---> Топик А                Топик Б
 |         ^        да  Раздел 0               Раздел 1
 |         |            [Пакет 0]              [Пакет 0]
 |         |            [Пакет 1]              [Пакет 1]
 -----  Неудача?        [Пакет 2]              [Пакет 2]
           ^                        |
           |                        | 
           |                        V
           -------------------  Брокер Kafka
``````

1. Для генерации сообщений понадобится создать объект `ProducerRecord`, включающий топик, в который мы собираемся отправить запись и значение
2. Можно так же задать ключ и разде, временную метку и/или набор заголовков
3. После отправки происходит сериализация объекта ключа и значения в байтовые массивы для отправки по сети
4. Если разделы явно не указаны, данные попадают в объект `Partitioner`
5. Объект `Partitioner` выбирает раздел,  в соответствии с ключом из `ProducerRecord`
6. Если раздел выбран, то производитель будет знать в какой топик и раздел должна попасть запись
7. После запись помещается в пакет записей, предназначенных ддя отправки в топик и раздел
8. За отправку пакетов записей соответствующему брокеру Kafka отвечает отдельный поток выполнения
9. После получения сообщений брокер отправляет ответ
10. В случае успеха возвращается объект `RecordMetadata` содержащий топик, раздел и смещение записи в разделе
11. При неудаче будет возвращено сообщение об ошибке

### 2. Обязательные свойства производителей
- `bootstrap.servers` - список пар host:port брокеров, исользуемых производителем для первоначального соединения с кластером
  Производитель может получать дополнительную информацию после начального соединения. Рекомендуется включить хотя бы два брокера
- `key.serializer` - имя класса, применяемого для сериализации ключени записей, генерируемых для отправки в Kafka
  Значением должно быть имя класса, реализующего интерфейс `org.apache.kafka.common.serialization.Serializer` 
- `value.serializer` - имя класса, используемого для сериализации значений записей

### 3. Пример создания нового производителя
```java
Properties kafkaProps = new Properties(); // (1)
kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");

kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // (2)
kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); 

producer = new KafkaProducer<String, String>(kafkaProps);// (3)
```

1. Начинаем с объекта `Properties`
2. Мы планируем использовать строки для ключа и значения сообщения, поэтому подойдет `StringSerializer`
3. Создаем новый поизводитель, задавая подходящие типы ключа и значения и передавая в конструктор объект Properties

### 4. Методы отправки сообщений
1. Сделать и забыть - Отправляем сообщение на сервер, после чего особо не волнуемся дошло или нет
   В случае ошибок или таймауста сообщение будет потеряно и информации о потере не будет
2. Синхронная отправка - Производитель Kafka всгда асинхронный - метод send() возвращает объект класса Future
   Можно воспользоваться методом get() для ожидания ответа
3. Асинхронная отправка - вызываем send(), которому передается функция обратного вызова при получении ответа

### 5. Пример отправки сообщений
```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France"); // (1)

try {
  producer.send(record); // (2)
} catch (Exception e) {
  e.printStackTrace(); // (3)
}
```

1. Производитель получает на фходе объекты `ProducerRecord`, поэтому начинаем с создания самого объекта
   Используется конструктор, принимающий на входе - название топика, ключ и значение
2. Для отправки используется метод send(), который возвращает объект класса Future
3. Выводит потенциальные ошибки

### 6. Синхронная отправка сообщений
При синхронной отправке тратится время на ожидаение ответа и блокируется весь поток выполнения
```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");

try {
  producer.send(record).get(); // (1)
} catch (Exception e) {
  e.printStackTrace(); // (2)
}
```

1. Используется метод Future.get() для ожидания ответа от Kafka
   Метод генерирует исключение в случае неудачи отправки записи.
    При отсутствии ошибок мы получим объект `RecordMetadata`
2. Если перед отправкой или во время отправки записи возникли ошибки, то мы получим исключение и выведем информацию о нем

### 7. Типы ошибок в KafkaProducer
1. Ошибки, которые можно исправить, отправив сообщение повторно (repitable)
   Например, ошибка соединения, ошибка "отсутствует ведущий узел для раздела"
2. Ошибки, которые невозможно исправить
    Например, "сообщение слишком велико"

### 8. Асинхронная отправка сообщения
Для асихронной отправки сообщений с сохранением возможности обработки различных сценариев ошибок производителя поддерживают функции обратного вызова при оправке записи

```java
private class DemoProducerCallback implements Callback { // (1)
  @Override
  public void onComletion (RecordMetadata recordMetadata, Exception e) {
    if (e != null) {
      e.printStackTrace(); // (2)
    }
  }
}

ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Biomedical Materials", "USA"); // (3)
producer.send(record, new DemoProducerCallback()); // (4)
```

1. Для использования функций обратного вызов понадобится класс, реализующий интерфейс `org.apache.kafka.clients.producer.Callback`
2. Если Kafka вернет ошибку, в функцию `onCompetion()` попадет непустое исключение
3. Записи остаются такими же как и при синхронном вызове
4. Передаем Callback при отправке записи

### 9. Разделы

+ [1. Зачем нужны разделы](#1-зачем-нужны-разделы)
+ [2. Пример создания сообщения с ключем](#2-пример-создания-сообщения-с-ключем)
+ [3. Что используется для балансировки сообщений](#3-что-используется-для-балансировки-сообщений)
+ [4. Реализация Partitioner](#4-реализация-partitioner)

#### 1. Зачем нужны разделы
1. Каждый топик может иметь 1 или больше разделов, которые распределяются по разным узлам кластера (брокерам)
Это позволяет нескольким потребителям считывать данные из одного топика одновременно
2. Если число потребителей меньше числа разделов, один consumer получает сообщения из нескольких разделов
3. Если потребителей больше, чем разделов, нескоторые consumer не получат никаких сообщений, пока общее количество потребителей не снизится до количества разделов
4. На пратике максимальное число разделов ограничивается размером сохраняемых сообщений, которые могут поместиться на одном узле
   Теоретически максимальное количество разделов может быть любым
5. Чтобы повысить надежность и доступность данных в кластере Kafka, разедлы могут иметь копии
6. Число разделов и коэффициент репликации можно настроить для всего класеа или для кадого топика отдельно


#### 2. Пример создания сообщения с ключем
```java
ProducerRecord<String String> record = new ProducerRecord<>("CustomerCountry", "Labratory Equipment", "USA")
```
без ключа
```java
ProducerRecord<String String> record = new ProducerRecord<>("CustomerCountry", "USA")
```

#### 3. Что используется для балансировки сообщений
Если ключ не указан, то запись будет отправлена в один из доступных рахделов топика случайным образом
Для балансировки сообщений по разделам будет применяться циклический алгорит (round-robin)
Начиная с весрии 2.4 циклический алгоритм является "липким". Это означает, что он будет заполнять пакет сообщений, отправленных в один раздел, прежде чем переключиться на следующий.

Если ключ указан, то будет вычислено хеш-значение с помощью собственного алгоритма хеширования, так что хеш-значение не изменяется при обновлении Java

#### 4. Реализация Partitioner
```java
import org.apache.kafka.clients.producer.Partitioner;
import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.PartitionInfo;
import org.apache.kafka.common.record.InvalidRecordException;
import org.apache.kafka.common.utils.Utils;

public class BananaPartitioner implements Partitioner {
  public void configure (Map<String, ?> configs) {} // 1()
  
  public int partition (String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
    int numPartitions = partitions.size();
    
    if ((keyBytes == null) || (!(ky instanceof String))) { // (2)
      throw new InvalidRecordException("We expect all messages to have customer name as key");
    }
    
    if ((String) key.equals("Banana")) {
      return numPartitions - 1; // Banana всегда попадает в последний раздел
    }
    
    // Другие записи рспределяются по разделам хеширования
    return Math.abs(this.murmur(keyBytes)) % (numPartitions - 1);
  }
}
```

1. Интерфейс объекта секционирования включает методы configure, partition и close.
2. Мы ожидаем только токовые ключи, иначе генерируем исключение

### 10. Заголовки

Записи могут включать в себя заголовки.
Заголовки могут содержать некоторые метаданные о записи
Используются например для указания источника данных в записи, а также для маршрутизации или отслеживания сообщений на основе информации заголовка

Представлены в виде коллекции "ключ/значение".
Ключи всегда являются строками, а значениями могут быть любые сериализованные объекты

```java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");

record.headers().add("privacy-level","YOLO".getBytes(StandardCharsets.UTF_8));
```

### 11. Перехватчики

Перехватчики используются для измененияповедения клиенского приложения, без изменения кода

ProducerInterceptop включают два ключевых метода:
- ProducerRecord<K, V> onSend(ProducerRecord<K, V> record) - метод будет вызван до того, как созданная запись будет отправлена.
    Переобпределяя метод можно получить информацию об отправленной записи и даже изменить ее
- void onAcknowledgement(RecordMetadata metadata, Exception exception) - метод будет вызван, если и когда ответит подтверждением на автоотправку

Примеры использования:
- Сбор информации для мониторинга и отслеживания
- Дополнение сообщения стандартными заголовками
- Редактирование конфиденциальной информации

Пример:
```java
public class CountingProducerIntercepor implements ProducerInterceptor {
  ScheduledExecutorService executorService = Executors.newSingleThreadScheduledExecutor();
  static AtomicLong numSent = new AtomicLong(0);
  static AtomicLong numAcked = new AtomicLong(0);

  public void configure(Map<String, ?> map) {
    Long windowSize = Long.valueOf((String) map.get("counting.interceptor.window.size.ms")); // (1)
    executorService.scheduleAtFixedRate(CountingProducerInterceptor::run, windowSize, windowSize, TimeUnit.MILLISECONDS);
  }

  public ProducerRecord onSend(ProducerRecord producerRecord) {
    numSent.incrementAndGet();
    return producerRecord; // (2)
  }

  public void onAcknowledgement(RecordMetadata recordMetadata, Exception e) {
    numAcked.incrementAndGet(); // (3)
  }
  
  public void close() {
    executorService.shutdownNow(); // (4)
  }
  
  public static void run() {
    System.out.println(numSent.getAndSet(0));
    System.out.println(numAcked.getAndSet(0));
  }
}
```

1. ProducerInterceptor - это настраиваемый интерфейс. Можно переопределить метод confgure и выполнить настройку перед вызовом любого другого метода
2. Когда запись отправлена, увеличиваем счетчик записей и возвращаем запись
3. Когда Kafka отвечает подтверждением получения, увеличивем счетчик подтверждений и не должны ничего возвращать
4. Метод вызывается когда производитель закрывается. В данном случае мы закрываем открытый поток. 

## END ---------------- Производитель ----------------

## Потребитель

+ [1. Группа потребителей](#1-группа-потребителей)
+ [2. Способы масштабирования](#2-способы-масштабирования)
+ [3. Как происходит перебалансировка разделов](#3-как-происходит-перебалансировка-разделов)
+ [4. Как потребители поддерживают членство в группе](#4-как-потребители-поддерживают-членство-в-группе)
+ [5. Что происходит когда потребители присоединяются к группу](#5-что-происходит-когда-потребители-присоединяются-к-группу)
+ [6. Статические участники группы](#6-статические-участники-группы)
+ [7. Создание потребителя](#7-создание-потребителя)
+ [8. Подписка на топик](#8-подписка-на-топик)
+ [9. Фиксация смещения](#9-фиксация-смещения)

### 1. Группа потребителей
Если несколько потребителей подписаны на один топик и относятся к одной группе, все они будут получать сообщения из различных подмножеств разделов группы

Пример:
Топик Т1 с 4мя разделами
    - Раздел 0
    - Раздел 1
    - Раздел 2
    - Раздел 3

Потребитель C1 - единственный потребитель в группе G1 и подписан на топик T1

Если мы добавим в G1 еще один потребитель C2
    то каждый потребитель будет получать сообщения только из двух разделов

Если в группе G1 будет 4 потребителя, то каждый из них будет читать сообщения из своего раздела

T1                        G1
- Раздел 0   ---->   - Потребитель 1
- Раздел 1   ---->   - Потребитель 2
- Раздел 2   ---->   - Потребитель 3
- Раздел 3   ---->   - Потребитель 4

Если же потребителей в группе G1 будет больше чем разделов в топике, то потребители часто будут простаивать и вообще не получать сообщения

### 2. Способы масштабирования
Чаще всего потребители выполняют операции с высокой задержкой, т.е. потребитель будет отставать от темпов поступления данных в топик
Основной метод масштабировани - добавление новых потребителей, каждый из которых отвечает лишь за часть разделов и сообщений

### 3. Как происходит перебалансировка разделов
Перебалансировка - передача раздела от одного потребителя другому
- Добавленный в группу потребитель начинает получать сообщения из разделов, за которые ранее отвечал другой потребитель
- То же самое происходит если потребитель останавливается или аварийно завершается
- Переназначение разделов потребителям происходит также при изменении топиков

Типы перебалансировки:
1. Безотлагательная перебалансировка - Все потребители прекращают потребление, отказываются от своих прав владения всеми разделами
   снова присоединяются к группе потребителей и получают совершенно новое назначение разделов
2. Совместная перебалансировка (инкрементная перебалансировка) - переназначение лишь небольшого подмножества разделов от одного потребителя к другому
    и позволяет потребителям продожать обработку записей из всех разделов, которые не были переназначены
    - Сначала лидер группы потребителей собщает всем потребителям, что они потеют право владения подмножеством свих разделов
    - Потребители прекращают потребление из этих разделов
    - Отказывается от своего права владния ими
    - Лидер назначает эти осиротевшие разделы их новым владельцам

### 4. Как потребители поддерживают членство в группе
Потребители отправляют назначенному координатором группы брокеру Kafka переодических контрольных сигналов (heartbeats)
Если потребитель длительное время не отправляет сигналы, время его сеанса истекает, координатор группы признает его неработающим и инициирует перебалансировку

### 5. Что происходит когда потребители присоединяются к группу
- Потребитель отправляет сигнал координатору группы запрос JoinGroup
- Первый присоединившийся к группе потребитель становится ведущим потребителем группы
- Ведущий потребитель группы получает от координатора список всех потребителей, которые недавно отправляли контрольные сигналы
- Для определения того, за какие разделы какой потребитель должен отвечать, используется реализация класса PartitionAssignor
- Происходит распределение разделов
- После распределения разделов лидер группы потребителей отправляет список назначений координатору группы, которые пересылает информацию потребителям

### 6. Статические участники группы

+ [1. Как настроить статического участника группы](#1-как-настроить-статического-участника-группы)
+ [2. Что происходит при присоединении, выключении участника](#2-что-происходит-при-присоединении-выключении-участника)
+ [3. Можно ли иметь два статического участника с одиннаковыми идентификаторами](#3-можно-ли-иметь-два-статического-участника-с-одиннаковыми-идентификаторами)
+ [4. В каких кейса использовать статических участников](#4-в-каких-кейса-использовать-статических-участников)

#### 1. Как настроить статического участника группы
Настроить потребителя с уикальным идентификатором `group.instance.id`

#### 2. Что происходит при присоединении, выключении участника
Когда потребитель впервые присоединяется к группе потребителей ему назначается набор разделов в соответствии со стратегией назначения разделов
Когда поребитель выключается, он не покидает группу автоматически - он остается членом до тех пор, пока его сессия не завершится
Когда потребитель снова присоединяется к группе, он распознается со своей статическом идентификацией и ему переназначаются те же разделы, которые он занимал ранее, без перебалансировки

#### 3. Можно ли иметь два статического участника с одиннаковыми идентификаторами
Нет. второй отребитель получит ошибку

#### 4. В каких кейса использовать статических участников
Когда приложение поддерживает локальное состояние или кеш и повторное создание кэша занимает много времени


### 7. Создание потребителя
Три обязательных свойства:
    bootstrap.servers - строка подключения к кластеру
    key.deserializer - класс для десериализации
    value.deserializer - класс для десериализации

Пример:
```java
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9092");
props.put("group.id", "CountryCounter");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);
```

### 8. Подписка на топик
```java
consumer.subscribe(Collections.singletonList("customerCountries")); //(1)
```
1. Создаем список, содержащий один элемент - название топика "consumerCountries"

Можно вызвать метод sbscribe с регулярным выражением для подписки на несколько топиков

```java
consumer.subscribe(Pattern.compile("test.*"));
```
!Note: При подписке через регулярное выражение, потребитель будет запрашивать весь список топиков и их разделов у брокеров через регулярные промежутки времени
Затем клиент будет использовать полученный список для обнаружения новых топиков, которые он включит в свою подписку


### 9. Фиксация смещения

+ [1. Что такое смещение](#1-что-такое-смещение)
+ [2. Как потребители фиксируют смещение](#2-как-потребители-фиксируют-смещение)
+ [3. Как влияет смещение на перебалансировку](#3-как-влияет-смещение-на-перебалансировку)
+ [4. Как работает автоматическая фиксация](#4-как-работает-автоматическая-фиксация)
+ [5. Синхронная фиксация смещения](#5-синхронная-фиксация-смещения)
+ [6. Асинхронная фиксация](#5-синхронная-фиксация-смещения)
+ [7. Сочетание синхронной и асинхронной фиксации](#5-синхронная-фиксация-смещения)
+ [8. Фиксация заданного смещения](#5-синхронная-фиксация-смещения)
+ [9. Прослушивание на предмет перебалансировки](#5-синхронная-фиксация-смещения)
+ [10. Особенности событий при совместной перебалансировке](#5-синхронная-фиксация-смещения)
+ [11. Использование `onPartitionsRevoked()`](#5-синхронная-фиксация-смещения)

#### 1. Что такое смещение
Фиксация смещения - это обновление текущей позиции потребителя в разделах
Kafka не фиксирует записи по отдельности
Потребители фиксируют последнее сообщение, которое они успешно обработали из раздела

#### 2. Как потребители фиксируют смещение
Они отправляют сообщение в Kafka, которое обновляет специальный топик `__consumer_offers`
`__consumer_offers` - содержит смещение для каждого из разделов

#### 3. Как влияет смещение на перебалансировку
После перебалансировки каждому из потребителей может быть назначен набор разделов, отличный от обрабатываемых ранее
Чтобы знать, с какого места продолжать работу, потребитель должен прочитать оттуда последнее зафиксированное смещение для каждого из разделов и продолжать оттуда

* Если зафиксированное смещение меньше смещения последнего обработанного клиентом сообщение, то расположенные между ними сообщения будут обработаны дважды
* Если зафиксированное смещение превышает смещение последнего обработаного клиентом события, то расположенные в этом промежутке сообщения будут пропущены группой поребителей

#### 4. Как работает автоматическая фиксация
При значени `enable.auto.commit = true` потребитель каждые 5с будет автоматически фиксировать самое последнее смещение, возвращенное клиенту метдом poll()
Значение 5с можно изменить `auto.commit.interval.ms`

В основе автоматической фиксации лежит цикл опроса.
    - При каждом опросе потребитель проверяет не пора ли выполнить фиксацию
    - Если да, фиксирует возвращенные при послежнем опросе смещения

Кейс:
После последней фиксации прошло 3с и потребитель вышел из строя
После перебалансировки выжившие потребители начнкт потреблять разделы, которые ранее принадлежали вышедшему из сроя брокуру
Они будут получать данные с последнего зафиксированного смещения
То есть события последних 3с будут обработаны дважды

#### 5. Синхронная фиксация смещения
Отключить автоматическую фиксацию можно `enable.auto.commit = false`
Простейщий способ фиксации `commitSync()`
Он фиксирует последнее возвращенное методом `poll()` смещение и сразу завершает выполнние процедуры

Пример:
```java
while(true) {
  ConsumerRecords<String, String> records = consumer.poll(timeout);
  
  for (ConsumerRecord<String, String> record: records) {
      System.out.printf("topic = %s, partition = %s, offset = %d, customer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value()); // (1)
  }
  
  try {
    consumer.commitSync(); // (2)
  } catch (CommitFailedEception e) {
    log.error("commit failed", e); // (3)
  }
}
```

1. Обработка записи состоит в выводе содержимого
2. После завершеия обработки всех записей текущего пакета вызываем `commitSync()` для фиксации последнего смещения
3. Метод `commitSync()` повторяет фиксацию до тех пор пока не возникнет непоправимая ошибка

#### 6. Асинхронная фиксация
Асинхронная фиксация в отличии от синхронной не блокирует основной поток.
Вместо того чтобы ждать ответа брокера на запрос фиксации, просто отправляем запрос и продолжаем работу

```java
Duration timeout = Duration.ofMillis(100);

while (true) {
  ConsumerRecods<String, String> records = consumer.poll(timeout);
  for (ConsumerRecord<String, String> record: records) {
      System.out.printf("topic = %s, partition = %s,
          offset = %d, customer = %s, country = %s\n",
          record.topic(), record.partition(), record.offset(),
          record.key(), record.value());
  }
  
  consumer.commitAsync(); // (1)
}
```
1. Фиксируем последнее смещение и продолжаем работу

Недостатки:
`commitSync()` будет повторять попытку фиксации до тех пор, пока она не завершится успешно или не возникнет ошибка, которую нельзя исправить путем повтора
`commitAsync()` повторять попыту не станет
    Причина этому то, что на момент получения ответа от сервера уже может быть успешно выполнена более поздняя фиксация

Функция обратного вызова
```java
Duration timeout = Duration.ofMillis(100);

while (true) {
  ConsumerRecods<String, String> records = consumer.poll(timeout);
  for (ConsumerRecord<String, String> record: records) {
      System.out.printf("topic = %s, partition = %s,
          offset = %d, customer = %s, country = %s\n",
          record.topic(), record.partition(), record.offset(),
          record.key(), record.value());
  }
  
  consumer.commitAsync(new OffsetCommitCallback() {
    public void onComplete(Map<TopicPartition,
      OffsetAndMetadata> offsets, Exception e) {
          if (e != null)
            log.error("Commit failed for offsets {}", offsets, e);
      }
  }); // (1)
}
```
1. Отправляем запрос на фиксацию и продолжаем работу, но в случае сбоя фиксации записываем в журнал информацию о себе и соответствующие смещения

#### 7. Сочетание синхронной и асинхронной фиксации
Если речь идет о последней фиксации перед закрытием потребителя и перебалнсировкой, то лчше позаботиться, чтобы она точно оказалась успешной

```java
Duration timeout = Duration.ofMillis(100);

try {
  while (!closing) {
      ConsumerRecords<String, String> records = consumer.poll(timeout);
      for (ConsumerRecord<String, String> record : records) {140  Глава 4. Потребители Kafka: чтение данных из Kafka
          System.out.printf("topic = %s, partition = %s, offset = %d,
              customer = %s, country = %s\n",
              record.topic(), record.partition(),
              record.offset(), record.key(), record.value());
      }
    consumer.commitAsync(); // (1)
  }
  
  consumer.commitSync(); // (2)
} catch (Exception e) {
  log.error("Unexpected error", e);
} finally {
  consumer.close();
}
```

1. Пока все нормально используем `commitAsync()`
2. При закрытии вызваем метод `commitSync()`, который станет повторять попытки вплоть до успещного выполнения или невосстановимого сбоя

#### 8. Фиксация заданного смещения
Если идет обработка пакета записей и смещение последнего полученного вами из раздела 3 в топике "покупатели" сообщения равно 5000
то можно вызвать метод `commitSync()` для фиксации смещения 5001 для раздела 3 в топике "покупатели"

```java
private Map<TopicPartition, OffsetAndMetadata> currentOffset = new HashMap<>; // (1)

int count = 0;

...

Duration timeout = Duration.ofMillis(100);
while (true){
  ConsumerRecords<String, String> records=consumer.poll(timeout);
  for (ConsumerRecord<String, String> record : records) {
      System.out.printf("topic = %s, partition = %s, offset = %d,
          customer = %s, country = %s\n",
          record.topic(), record.partition(), record.offset(),
          record.key(), record.value()); // (2)

      currentOffsets.put(
          new TopicPartition(record.topic(), record.partition()),
          new OffsetAndMetadata(record.offset()+1, "no metadata")); // (3)
      
      if (count % 1000 == 0) { // (4)
        consumer.commitAsync(currentOffsets, null); // (5)
      }
      
      count++;
  }
}
```

1. Ассоциативный словарь для отслеживания смещений вручную
2. Заглушка вместо реальной обработки записей
3. После чтения каждой записи обновляем словарь смещений, указывая смещение следующего намеченного для обработки сообщения.
   Зафиксированного смещение всегда должн быть сещением следующего сообщение, которое будет прочитано вашим приложением.
   Именно с этого места начинаем чтение в следующий раз
4. Фиксируем текущие смещения через каждые 1000 записей
5. Для фиксации можно вызвать как `commitAsync()` так и `commitSync()`

#### 9. Прослушивание на предмет перебалансировки
Если известно, что раздел вот-вот перестанет принадлежать данному потребителю, то желательно зафиксировать смещения последних обработанных событий
А так же закрыть соеденинения с бд и т.д.

Для работы во время смены разедлов необходимо передавть объект `ConsumerRebalanceListener` при вызове метода `subscribe()`

`ConsumerRebalanceListener` имеет три доступных для реализации метода:
1. `public void onPartitionsAssigned(Collection<TopicPartition> partitions)` 
   вызывается после переназначения разделов потребителю, но до того как он начнет получать сообщения.
    Здесь можно подготовить и загрузить любое состояние, которое будет использоваться с разделом, находим правильное смещение если это необходимо
    Любая подготовка должна выполнится в течение `max.poll.timeout.ms`
2. `public void onPartitionsRevoke(Collection<TopicPartition> partitions)`
   вызывается, когда потребитель должен отказаться от разделов, которыми он ранее владел
   либо в результате перебалансировки
    либо при закрытии потребителя
    Метод вызывается до начала перебалансировки и после того, как потребитель перестал получать сообщения
    Если используется совместный алгоритм перебалансироки, метод вызывается в конце перебалансировки только с тем подмножеством разлделов, от которых потребитель должен отказаться
3. `public void onPartitionsLost(Collection partitions)`
   вызывается только при использовании совместного алгоритма перебалансировки и только в исключительных случаях
    когда разделы были назначены другим потребителям без предварительного отзыва алгоритмо перебалансировки
    Здесь очичаются все состояния или ресурсы, которые использовались с этими разделами

#### 10. Особенности событий при совместной перебалансировке
1. Метод `onPartitionsAssigned()` будет вызываться при каждой перебалансировке. Если нет новых разделов, назанченных пользователю, он будет вызван с пустой коллекцией
2. Метод `onPartitionsRevoked()` будет вызываться в обычных условия пребалансировки, но только в том случае, если потребитель отказался от владения разделами 
3. Метод `onPartitionsLost()` будет вызываться в исключительных условиях перебалансировки, и к моменту его вызова у разделов в коллекции уже будут новые владельцы

#### 11. Использование `onPartitionsRevoked()`
```java
private Map<TopicPartition, OffsetAndMetadata> currentOffsets = new HashMap<>;
Duration timeout = Suration.ofMills(100);

private class HandleRebalance implements ConsumerRebalanceListener { // (1)
  public void onPartitionsAssigned (Collection<TopicPartition> partitions) { // (2)
    
  }
  
  public void onPartitionsRevoked (Collection<TopicPartition> partitions) {
    System.out.println("Lost partitions in rebalance. Committing current offsets: " + currentOffsets);
    consumer.commitSync(currentOffsets); // (3)
  }
}

try {
  consumer.subscribe(topics, new HandleRebalance()); // (4)
 
  while (true) {
    ConsmerRecords<String, String> records = consumer.poll(timeout);
      
    for (ConsumerRecords<String, String> record: records) {
      System.out.printf("topic = %s, partition = $s, offset = %d, customer = %s, country = %s\n", record.topic(), record.partition(), record.offset(), record.key(), record.value());
      currentOffsets.put(
        new TopicPartition(record.topic(), record.partition()),
        new OffsetAndMetadata(record.offset() + 1, null)
      );
    }
    consumer.commitAsync(currentOffsets, null);
  }
} catch (WakeupException e) {
  // Игнорируем, посколько закрываемся
} catch (Exception e) {
  log.error("Unexpected error", e);
} finally {
  try {
    consumer.commitSync(currentOffsets);
  } finally {
    consimer.close();
    System.out.println("Closed consumer and we are done");
  }
}
```

1. Начинаем реализовывать класс `ConsumerRebalanceListener`
2. При назначении нового раздела не требуется ничего делать, просто читаем сообщение
3. Когда потребитель вот-вот потеряет раздел из-за перебалансировки, необходимо зафиксировать смещения
    Фиксируем смещения для всех разделов
4. Передаем `ConsumerRebalanceListener` в метод `subscribe()`

## END ---------------- Потребитель ----------------